=======================================
######### AWS STORAGE SERVICE #########

## AWS S3
- It is Simple Storage service 
- It is a scalable, high-speed, low-cost web-based service designed for online backup and archiving of data and application programs. 
- It allows to upload, store, and download any type of files up to 5 TB in size

## AWS Elastic File System
- Fully managed, scalable, and sharable storage among thousands of EC2 instances.

## Glacier
- Secure, durable, and extremely low-cost solutions for backup and archiving.

## Storage Gateway
- Seamlessly connect on-premise applications or services with the AWS cloud storage.

## 
=======================================
##### SIMPLE STORAGE SERVICE(S3) ######

> S3 is one of the first services that has been produced by aws.
> S3 provides developers and IT teams with secure, durable, highly scalable object storage.
- It is easy to use with a simple web services interface to store and retrieve any amount of data from anywhere on the web.

## What is S3?
> S3 is a safe place to store the files.
- It is Object-based storage, i.e., you can store the images, word files, pdf files, etc.
- The files which are stored in S3 can be from 0 Bytes to 5 TB (i.e unlimited storage)

> Files are stored in Bucket. A bucket is like a folder available in S3 that stores the files.

> S3 is a universal namespace, i.e., the names must be unique globally. Bucket contains a DNS address. Therefore, the bucket must contain a unique name to generate a unique DNS address.
If you create a bucket, URL look like:
https://s3-eu-west-1.amazonaws.com/acloudguru 


> If you upload a file to S3 bucket, then you will receive an HTTP 200 code means that the uploading of a file is successful.

## ADVANTAGES OF AMAZON S3

1. Create Buckets: Firstly, we create a bucket and provide a name to the bucket. Buckets are the containers in S3 that stores the data. Buckets must have a unique name to generate a unique DNS address.

2. Storing data in buckets: Bucket can be used to store an infinite amount of data. You can upload the files as much you want into an Amazon S3 bucket, i.e., there is no maximum limit to store the files. Each object can contain upto 5 TB of data. Each object can be stored and retrieved by using a unique developer assigned-key.

3. Download data: You can also download your data from a bucket and can also give permission to others to download the same data. You can download the data at any time whenever you want.

4. Permissions: 
- You can also grant or deny access to others who want to download or upload the data from your Amazon S3 bucket. Authentication mechanism keeps the data secure from unauthorized access.

5. Standard interfaces: S3 is used with the standard interfaces REST and SOAP interfaces which are designed in such a way that they can work with any development toolkit.

6. Security: Amazon S3 offers security features by protecting unauthorized users from accessing your data.

### S3 is a simple key-value store
S3 is object-based. Objects consist of the following:

1. Key: It is simply the name of the object. For example, hello.txt, spreadsheet.xlsx, etc. You can use the key to retrieve the object.

2. Value: It is simply the data which is made up of a sequence of bytes. It is actually a data inside the file.

3. Version ID: Version ID uniquely identifies the object. It is a string generated by S3 when you add an object to the S3 bucket.

4. Metadata: It is the data about data that you are storing. A set of a name-value pair with which you can store the information regarding an object. Metadata can be assigned to the objects in Amazon S3 bucket.

5. Subresources: Subresource mechanism is used to store object-specific information.

6. Access control information: You can put the permissions individually on your files.

===================================
### Block versus object storage ###

## BLOCK STORAGE
> Block storage is SUITABLE FOR TRANSACTIONAL DATABASES, random read/write loads, and structured database storage

> Block storage divides the data to be stored in evenly sized blocks (data chunks), for instance, a file can be split into evenly sized blocks before it is stored 

> Data blocks stored in block storage would NOT CONTAIN METADATA (date created, date modified, content type...etc)

> Block storage only keeps the address(index) where the data blocks are stored

## OBJECT STORAGE
> It stores the files as a whole and does not divide them

> In object storage, an object is:
- A file/data itself
- Its metadata (data created, modified, security attributes, content type.etc)
- Object's global unique ID

> The Object Global Unique ID, Is a unique identifier for the object (can be the object name itself), and it must be unique such that it can be retrieved disregarding where its physical storage location is

> Examples for Objects,
- Photos, Videos, Music, Static Web Content, Data backups (snapshots), Archival images
- ANY DATA THAT CAN BE INCREMENTALY UPDATED and will not have a lot of writes/updates

> OBJECT STORAGE CAN GUARANTEE HIGH AVAILABILITY AND DURABILITY 
- data copies are stored on multiple, geographical distributed location 
- object storage cannot be mounted on a drive or directory, directly to an EC2 instance 
- object storage is a perfect solution for data growth storage problem
=======================================
###### DATA CONSISTENCY MODEL ####### v2
> Data consistency is relevant when we are considering copies of the same data object store over distributed system

> when the copies of data(stored on different systems) are read at the same time from different nodes, consistency level referred to how consistent will they be returned data (from the read), is it going to be 100% the same or slightly different?

####### STRONG CONSISTENCY ####
> Sometime also referred as immediate consistency

> Read from different data stores for listen data returns the exact same information
> Any update made to the date object in any storage node will be propagated and updated on all other storage nodes before the data is made available for read by clients
> Requires a locking mechanism to block read until the data is propagated and updated on all nodes
> Is good for transactional database and real time system with consistent writes
> Has limited scalability and reduced availability

#### EVENTUAL CONSISTENCY #####
> Read from different data stores for the same data result different returns
> There is no locking mechanism, if data is updated to an object, an immediate read from different note will not return the same data
- with time and as the changes/updates get propagated and updated on all other storage note, the reads will be will eventually consistent

> Eventually consistent can virtually provide unlimited 
- scalability 
- availability 
- data durability

#### S3 CONSISTENCY LEVEL
> S3 Provides:
- READ-AFTER-WRITE (IMMEDIATE OR STRONG) CONSISTENCY of PUTS of new objects (new object loads to S3)

> EVENTUAL CONSISTENCY FOR OVERWRITE data PUTS and DELETES (for Changes/updates to existing Objects in S3)

> Updates to an Object are atomic, i.e when you run a PUT for an object then you read (GET) that object, you will either get the updated object or the old one (before the update), you will NEVER GET PARTIAL OR CORRUPT DATA
=======================================
########### S3 ############## v3

> S3 is a storage for the internet. It has a simple web service interface for simple storing and retrieval of any amount of data, anytime, from anywhere on the internet 
> it is object based storage and not a block storage
> S3 has a DISTRIBUTED DATA-STORE ARCHITECTURE where object are redundant stored in multiple location

#### S3 BUCKETS ####
> Data is stored in buckets 
- It can be viewed as a flat container for objects that DOES NOT PROVIDE HIERARCHICAL OF OBJECT
- We can use object key(name) to mimic folders in a bucket when using the AWS console

> You can store unlimited object in your bucket but an object cannot exceed 5TB
> CAN CREATE FOLDER IN YOUR BUCKET (available through console only)
> You cannot create nested buckets (a bucket inside another)
> Bucket ownership is not transferable
> It is recommended to access S3 through SDK or API (console internally use API too)
> An S3 bucket is region specific
> You can have upto 100 buckets (soft limit) per account

> An S3 bucket has properties including 
- access permission 
- versioning status 
- storage classes

#### S3 BUCKET NAMING RULE #####
> S3 bucket names(keys) are globally unique across all region 
- bucket name cannot be changed after they created 
- if a bucket is deleted its name become available again to you or another account to use 
- bucket names must be at least 3 or no more than 63 character long 

> bucket names are part of the URL is to access bucket

> Bucket name must be a series of one or more label(mymain.bucket)
- Adjacent label are separated by a single period 
- bucket name can contain lowercase letter, numbers and hyphen
- each label must start and end with a lowercase letter or a number

> Bucket name must not be formatted as an IP address
=======================================
###### S3 buckets sub resources ####### v4
> Amazon S3 supports various option for you to configure your bucket 
- Amazon S3 support subject sources for you to store and manage the bucket configuration information 
- using the Amazon S3 API you can create and manage these resources 
- you can also use the console or AWS SDK

> By default a bucket its object and related sab resources are all private that is by default only the owner has access to the bucket and storage object

> Sub-resources for S3 bucket includes:
- LIFECYCLE : to decide and object lifecycle management
- WEBSITE : to hold configuration related to static website hosted in it
- VERSIONING: keep object version as it change
- Access control list(ACLs) 
- bucket policies

## S3 bucket DNS names
> The name is simply two parts 
- bucket region endpoints/bucketname
EX: https://s3-eu-west-1.amazonaws.com/cloudbucket1

> S3 buckets region
> For better performance low latency help to minimise cost, create the S3 bucket closer to your client DC are source of data to be stored
=======================================
############ S3 objects ############### v5

> An object size stored in S3 bucket can be 0 byte upto 5tb
> Each object is stored and retrieved by unique key
> An object is a 330 uniquely identified and address through
> Service centre point bucketname object key optional ITI object version
> Object store in S3 bucket in a region will never leave that region
-  unless you specify move them to another reason or enable cross region replication
> S3 PROVIDE HIGH DATA DURABILITY, object are redundantly stored on multiple devices across multiple facility in Amazon S3 region where the bucket exist

## S3 object sub resources
1. Access Control List :
- to define guarantee and permission granted to the object

2. Torrent 
- used by S3 in case bittorrent tries to download the object
=======================================
#### S3 RESOURCES AND SUB RESOURCES ### v6

> Bucket and object are primary S3 resources 
- each has its own sub resources

> Buckets sub-resources are lifecycle 
- Lifecycle, website, versioning, ACL and policies, Cross origin Resource sharing(CORS) and logging(bucket access log)

> Object sub-resources are 
- ACL and restore(restoring an archive)

> Operations on S3 are either bucket level operation or object label operation

## S3 RESOURCE OWNER

> By default all Amazon S3 resources are private 
- only a resource owner can access the resources

> resource owner refer to the account that create the resources.
- for example account that you use to create buckets and objects owns those resources

> If you create an AWS IAM user in your AWS account you are the parent owner 
- if the IAM USER UPLOAD AN OBJECT, THE PARENT ACCOUNT OWNS THE OBJECT

> A bucket owner can grant cross-account permissions to another AWS account(or user in another account) upload object. 
- AWS account that upload the object own them

> The bucket owner does not have permission on the object that other account own with the following exception
- The bucket owner pays the bill. He can deny access to any object regardless of who owns them
- The bucket owner can delete any object in the bucket, regardless of who owns them.
- The bucket owner  can archive any objects or restore archive object regardless of who owns them

## Managing access to resources(access policy option)
> managing access refers to granting other (AWS account and user) permission to perform the resources operations by writing an access policy

> You can grant S3 bucket/object permission to 
- individual user 
- AWS accounts 
- make the resource public, grant permission to everyone (also referred as anonymous access) 
- or to all authenticated user (user with AWS credentials)
=======================================
######### S3 access policy ############ v7

> Access policy describe who has access to what. 
- You can associate and access policy with a resource (bucket/object) OR user

>  Amazon S3 access policy are as follow: 
1. Resource based Policy
2. User Access Policy 

#### 1. S3 RESOURCE BASED POLICY ####
> bucket policy and access control list are resource-based because you attached them to your Amazon S3 resources

## 1a. ACL-BASED ACCESS POLICY (buckets and objects ACLs)
- each bucket and object can have an ACL associated with it
> An ACL is a list of grants i.e. identifying guarantee(who) and permission granted(what)
> You use ACL to grant basic read/write permission to other AWS account

##1b. BUCKET POLICY 
> for your bucket you can add a bucket policy to grant other AWS account or IAM user permission FOR THE BUCKET AND THE OBJECT in it
- any object permission apply only to the object that the bucket owner creates 
- bucket policy supplement and in many cases replace ACL based access policy

###### 2. S3 USER ACCESS POLICY #######

> You can use AWS IAM to manage access to your Amazon S3 resources

> Using IAM, you can create IAM user, group and role in your account and attach access policy to them granting them access to AWS resources including Amazon S3

> You cannot grant anonymous permissions in any IAM user policy because the policy is attached to a user

> User policy can grant permission to a bucket and object in it

## How does S3 evaluate (allow/deny) a request for an S3 resource operation (Bucket or Object Operation)

> S3 evaluates:

User Context:
> S3 checks whether the user attached policies allows the request, so basically whether the parent account allows the operation to the IAM user or not
- If the user is the root account, this validation is skipped

Bucket Context:
- S3 validates whether the bucket owner (can be the same parent account or another AWS account) has allowed the requested operation to this user

- Bucket policy, Bucket ACL, and Object (if Object operation) are All checked

Notes:
> If the parent AWS account owns the resource (bucket or object), it can grant resource permissions to its IAM user by using either the user policy or the resource policy.

> If the bucket and object owner is the same,
- Access to the object can be granted in the bucket policy, which is evaluated at the bucket context.

> If the owners are different,
- The object owners must use an object ACL to grant permissions.

> If the AWS account that owns the object is also the parent account to which the IAM user belongs, it can configure object permissions in a user policy, which is evaluated at the user context.
=======================================
####### Bucket ACL permissions ######## v8

> Amazon S3 access control list(ACL) enable you to manage access to bucket and object

> Each bucket and object has an ACL attached to it as a sub-resources
- It define which account(grantee) or pre-defined S3 groups are granted access and the type of access
- You can not provide permissions to the individual IAM user
- Grantee accounts (cross account access) can then delegate access provided by other account to their individual user

> When you create a bucket or an object, Amazon S3 create a default ACL that grants the resources owner full control over the resources

### AWS S3 predefine groups
> Amazon S3 has a set of predefined groups that are

1. Authenticated user group 
- this group represent all AWS account. 
- Access permission to this group allow any AWS account to access the resources. 
- However all request must be signed(authenticated) 
- when you grant access to the authenticated user group any AWS authenticated user in the world can access our resources

2. All user group
> access permission to this group allows anyone in the world access to the resources 
- the request can be signed(authenticated) or unsigned(anonymous)
- unsigned request omit the authentication header in the request 
- AWS highly recommend that you never grant the 'all user group' WRITE, WRITE_ACP OR FULL_CONTROL permission

3. Log delivery group
- Write permission on a bucket enable this group to write server access logs
=======================================