######## AWS DATABASE SERVICE #########

## RDS
## Amazon Aurora
## DynamoDB
## AWS Redshift
## Amazon ElastiCache  

=======================================
############## AWS RDS ################ v4
> It is fully managed relational DB engine service where AWS is responsible for below:
- Security and patching of the DB instances
- Automatic backup for DB instance (defaults setting)
- Software update for the DB engine
- Easy scaling for storage and compute as required
- If selected multiple-AZ with synchronous replication between the active and standby DB instance
- Automatic failover if multiple-AZ options was selected
- Providing the ability to create DB read replicas for DB read scaling( intensive free deployment)

> Every DB instance has a weekly maintenance window 
- if you do not specify one at the time you created the DB instance 
- it will choose one randomly for you that is 30 minute long
=======================================
## AWS is not responsible for
- Managing DB setting 
- building a relational DB schema 
- DB performance tuning

## Supported relational DB engine
- MS SQL server, 
- Oracle 
- postgreSQL 
- mariaBD, 
- aws Aurora, 
- mysql

## 2 Licensing model
1. Bring your own licence
2. Licence included

##RDS LIMITS
> Up to 40 DB instances per account
- 10 of this 40 can be Oracle or MS SQL server under licence included model

> Under BYOL model, all 40 can be any DB engine you need 

##RDS instance storage
> Amazon RDS use EBS volume not instance store for DB and logs storage

> General purpose storage used for DB works with moderate I/O requirements
> Provision IOPS RDS storage use for high performance OLTP workload
> Magnetic RDS storage used for small DB workloads

##Maximum storage capacity for RDS DB instances
> Upto 4tb for my SQL server
> upto 6TB for the the rest of supported RDS DB engines

> Both Oracle and sqL Server db engines have limits to how many DB that can run per instance. 
- Primarily, this is due to the underlying technology being proprietary and reqairing specific licensing to operate. 
- The database engines based on Open Source technology such as Aurora, MYSQL, MariaDB or PostgresQL have no such limits.

=======================================
######### MULTI-AZ RDS OPTION #########

> You can select the multi-AZ option during RDS DB instance launch

> RDS service CREATE A STANDBY INSTANCE IN A DIFFERENT AZ IN THE SAME REGION and configure SYNCHRONOUS replication between the primary and standby

> we/app cannot read and write to the standby RDS DB instance

> you cannot dictate/select which AZ in the region will be chosen to create the standby DB instance 
- we can view which AZ is selected after the standby is created

> depending on the instance class, it may take 1 to few minutes to failover to the standby instance 
- It is recommended to implement DB connection retries in appl, 
- App may take few minute to switch to standby in case of failure.

> AWS RECOMMENDATION TO USE PROVISIONED IOPS INSTANCES FOR MULTI-AZ RDS INSTANCES
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##### FAILOVER TRIGGER ######

> Failover may be triggered when
- Loss of primary AZ or primary DB instance failure
- Loss of network connectivity to primary
- Compute(EC2) unit failure on primary
- Storage(EBS) unit failure on primary
- Primary DB instance is changed
- Patching the OS of the DB instance

- Manual failover(reboot with failover on primary)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## MULTI-AZ FAILOVER LOGISTICS

> during failover the CNAME of the RDS DB instance is updated to map to the standby IP address 
- this is why it is recommended to use endpoint to reference DB instance and not its IP addresses

> CNAME does not change because the RDS endpoint is not changed

> RDS endpoints does not change by selecting multi-AZ option
-  however the primary and standby instance will have different IP address given they are in different AZs
- Hence it is always recommended that do not use the IP address to point to your multi-AZ RDS instance rather use the endpoint

> This is very helpful in a failover scenario the primary will fail to the standby i.e. IP address of RDS instance will change
- Referencing by endpoint means there is no change(endpoint wise) when a failover happened, so no disruptions or manual intervention to facilitate RDS DB instance access in a failover scenario
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## MULTI-AZ RDS Manual failover and reboot
> In multi-AZ deployment, you can only initiate a manual RDS DB instance failover(primary to secondary) when rebooting
- This is by selecting the "reboot with failover" reboot option on the primary RDS DB instance

> A DB instance reboot is required for changes to take effect when we change the DB parameter group or static DB parameter
- This reboot restart the DB engine

> The DB parameter group is a configuration container for the DB engine configuration
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## MULTI-AZ RDS EVENT NOTIFICATIONS 
> You will be alerted by a DB instance event when a failover occurs

> AWS RDS uses AWS SNS to send RDS event via SNS notification
- we can use API calls to the RDS service to list the RDS events in the past 14 days(DescribeEvents API)
- You can view past 14 days events using CLI
- Using AWS console, you can only view RDS event for the last one day i.e 24 hour
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## PROCESS THAT HAPPENED ON THE STANDBY FIRST
> The following procedure are done on the standby first then on primary
- OS patching
- system upgrades 
- DB scaling

> in multi-AZ snapshot and automatic backup are done on the standby instance to avoid I/O suspension on primary instance
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Multi-AZ deployment maintenance
> The sequence is as follow 
- maintenance on standby is performed 
- standby promoted to primary 
- maintain is performed on old primary (current standby)

## Version upgrade
> You can manually upgrade DB instance to a supported DB engine version from AWS console as follows

RDS -> DB instance -> modify DB instance -> set DB engine version

> By default, change will take effect during the next maintenance window
> You can force an immediate upgrade if you need to

> In multi-AZ deployments:
- Version upgrade will be conducted on both primary and standby at the same time, which will cause an outage (unavailability of both)
> Advised to do during change/maintenance window

## Security group and NaCl
> In a multi-AZ scenario make sure that SG and NACL will allow app server to communicate with both primary and standby instance 
- in case of a failure failover the standby become the primary
=======================================
##### DB AUTOMATIC BACKUP OR MANUAL SNAPSHOT 
> These are the two method to backup and restore your RDS DB instances
1. AWS RDS automatic backups
2. user intiated manual backup

> either one backup up the entire DB instance and not just the individual DB
> either one create a storage volume snapshot of your entire DB instance not just the individual database
> You can make copies of automatic backup and of manual snapshot

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##### DB AUTOMATED BACKUPS ######

>  Automated backup by AWS, back up DB data to multi-AZ to provide for data durability
> Are labelled automated in AWS console (easily distinguishable)
> Stored in Amazon S3
> Multi-AZ automatic backup will be taken from the standby instance not the primary
> The DB instance must be in "active" state for the automatic backup to happen 
- if in any other state like "storage_full" state the automatic backup will not happen

> Automatic backup (not the manual one) are used for point-in-time DB instance recovery

> It can RESTORE THE DB UP TO 5 MIN IN TIME, using the DB transaction logs and the automated snapshot

> RDS automatically backup the DB instance daily, by creating a storage volume snapshot of DB instance (full daily snapshot), including the DB transaction logs(modifications) which are critical to be able to restore upto last 5 minutes in time
- You can choose when during the day this is done (backup window)

> No additional charge for RDS backing up DB instance
> ENABLED BY DEFAULT, we can disable it by setting retention period to 0

> During daily backup window, I/O MAY BE SUSPENDED (for standalone RDS deployment)
> For multi-AZ deployment, backup are taken from the standby DB instance (true for MariaDB, mySQL, Oracle, PostgreSQL)

>> Automatic backup deleted when we delete RDS DB instance

> Automatic backup are currently supported only for InnoDB storage engine for MySQL (and not for myISAM engine)
> Use to automatic backup with other MySQL DB storage engines including ISAM, may lead to unpredictable behaviour during restoration

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
###### DB RETENTION PERIOD ######
> The period of time AWS keep the automatic backup before deleting them
- 7 days (by default) is configured from the AWS console for all DB engine (except Arora default is one day regardless how it was configured)

> 1 day is configured from API or CLI (for all DB engine including Arora)
> You can increase it up to 35 days
> Value of 0 disabled automatic backup completely

> A DB outage if you change your retention period from 0 to non-zero value for the other way around from non-zero to 0 value
=======================================
##### DB SUBNET GROUP ###### v9

> Is a collection of subnet in a vpc that you want to allocated for DB instance launched in the vpc
> Is DB subnet group must have at least one subject in each easy in a reason
> Even if you are starting with standalone RDS instance configure the subnet group with the subnet in each easy in the reason
> This will facilitate launching your standby instance in the subnet group when you opt for multiple easy deployment
> during creating your RDS instance you can select a preferred easy and specify which subnet group and subnet group of TAT group for your RDS DB instance
> 10 audio service will allocate an IP address in that subnet to your RDS instance
> And then audio service will create and attached to the RDS instance and assign the above IP address to it
=======================================
### ENCRYPTION OF EXISTING UNENCRYPTED RDS INSTANCE v10
 
> You cannot encrypt an existing unencrypted DB instance

> To do that 
1. you need to create a new encrypted instance and migrate you data to it (from the unencrypted to the encrypted)
2. Restore from backup/snapshot into a new encrypted RDS instance

### App to DB instances encryption
> RDS supports SSL encryption for communication between the app instance and the RDS DB instance
- RDS generates a certificate for the instance which is used to encrypt this communication
- RDS service supports encryption at rest for all DB engine using AWS KMS

## RDS DB encryption at rest
> For an encrypted at rest DB instance
- All its snapshot
- Backup
- Data at storage(on the DB instance)
- Read replica related from the DB instance

- All are encrypted as well
- Encryption/decryption is handled transparently

## RDS DB instance security best practice
> Use AWS IAM account to control access to RDS API action
> Assign an individual IAM account to each person who manages RDS resources
> Grand the least permission required by each user to perform the assigned duties
> Use IAM groups to manage/grant permission to multiple user at a time
> Rotate your IAM credential regularly
=======================================
##### RDS Billing  ###### v11

> No upfront costs

> You pay for:
- DB instance hours (partial hours charged as full hours)
- EBS Storage GB/month.
- I/O requests/month - for Magnetic RDS storage Instance only
- Provisioned IOPS/month – For RDS Provisioned IOPS SSD instance
- Internet data transfer
- Backup Storage that is in S3 (DB backups, and Active manual Snapshots)
  - This increases by increasing DB backups retention period
  - Backup storage for automated RDS backups (not the manual snapshots) up to the Provisioned RDS instance's EBS volume size (EBS volume) is free of charge

## RDS Billing – Multi-AZ deployments
> AWS will charge for the following (in addition to the single AZ DB instance charges)
- Multi-AZ DB hours
- Provisioned Storage (Multi-AZ)
- Double write I/0s (writing to the Active/Primary, and-Replication from Primary to Standby)
- You are not charged for DB data transfer during replication fröm primary to standby
- Your DB storage does not change between Standalone and Multi-AZ deployments (same DB and same AWS Storage volume for that DB in multiple AZs for durability)

## Free Tier

> Single AZ:
- 750 Micro Instance Hours/month for each account for 1 year
- For ORACLE you need to BYOL

##### RESERVED DB INSTANCES (RIs) #####
> Similar to EC2 Reserved Instances
> DB RIs ARE "REGION" SPECIFIC NOT AZ SPECIFIC
> One or three year term options

> Each reservation must be specific in:
- DB Engine
- DB Instance class
- Multi-AZ option
- License Model
- Region
  - For RDS RI pricing to apply, an Exact RDS instance must be created on-demand, exact on all above (DB Engine, Instance class, Multi AZ option, License model, and region)

> You can NOT move RDS RIs between regions
> You can move RDS RIs between AZs in the same region
> You can NOT cancel an RDS RI's reservation
=======================================
####### Read Replicas ######### v12

> When the required read I/O capacity is reached but still more I/O capacity is required for heavy/intensive read applications, read replicas can come in handy

> Read replica is a replica of the primary RDS DB instance, but they can only be used for read actions

> Primary DB instance becomes the source of the replication to this read replica

> The data is first written to the source/primary DB Instance, then using asynchronous replication, it gets replicated to the read replica i.e there is a time lag between when the data is written to the primary and when it gets replicated to the read replica

> Multi-AZ with read replicas can be combined in one deployment
- NOT POSSIBLE TO CREATE REPLICA of READ REPLICAS 

> Read replicas can be created from the console or API

> AUTOMATIC BACKUPS (RETENTION PERIOD NOT ZERO) MUST BE ENABLED AND REMAIN ENABLED FOR READ REPLICAS TO WORK

> IS SUPPORTED WITH TRANSACTIONAL DB STORAGE ENGINES, and are supported on InnoDB engines not MYISAM (MYMAPO):
- MYSQL
- MariaDB
- PostegreSQL

> Each of these DB engines support up to 5 read replicas per source/primary DB instance

## Read Replicas – Use cases
> Shifting read intensive applications such as Business (or Sales) reporting, or Data Warehousing to read from read replicas as opposed to overload the primary DB
> Scaling beyond the I/O capacity of your main DB instance for read-heavy workloads
> Service read traffic while the source is unavailable

## Creating Read Replicas
> It can be done from API or AWS console
> The AZ where you want the read replica to be can be specified
> The read replica's storage type or instance class can be different from the source DB instance
> DB engine type can not be change though, it is inherited from the source (primary) DB instance
> Connecting to the DB engine on the read replica is possible, the same way (DB console) you connect to the primary DB instance
> If you scale the source DB instance, you should also scale the Read Replicas

> You cannot have more than four instances involved in a replication chain.
> If the source instance of a Multi-AZ deployment fails over to the secondary, any associated Read Replicas are switched to use the secondary as their replication source.

> You must explicitly delete Read Replicas, using the same mechanisms for deleting a DB instance.
 o If you delete the source DB instance without deleting the replicas, each replica is promoted to a stand-alone, single-AZ DB instance. 

> If you promote a MYSQL or MariaDB Read Replica that is in turn replicating to other Read Replicas, those Read Replicas remain active.

> If replication is stopped for more than 30 consecutive days, either manually or due to a Rplication error, Amazon RDS terminates replication between the master DB instance and all Read Replicas

======================================
##### v13

## Cross Region Read Replicas
> You can create read replicas in another region for MYSQL, MariaDB, PostgreSQL (but not for Aurora DB)
- Uses Asynchronous replication
- This can be used in improving DR capabilities by providing a lower RPO in case of a regional failure
- It can also help in case you have a requirement of Analytics to run in a different region (B) for a DB in region A.

## Read Replicas of Read Replicas
> MYSQL and MariaDB (MyMa):
- Allow for creating read replicas of the read replicas (second/third tier read replicas)

## Promoting Read replicas to Standalone DB instance
> You can promote a read replica into a standalone/single AZ database instance
- This is true for MYSQL, MariaDB, PostgreSQL (MyMaPo)

> Promotion process takes several minutes because the DB will reboot before the promoted replica becomes available as a standalone DB instance (allow for read/write, snapshots/backups...etc)

> The promoted replica into a standalone DB instance willPretain:
- Backup retention period
- Backup window
- DB parameter group

> In case of multiple read replicas (MYSQL, MariaDB), Promoting one to a standalone DB instance does not affect the other read replicas, those will continue to read from the former primary (source DB instance)

=======================================
##### v14

## Storage Scaling
> You can scale an RDS storage up only, you can not decrease or scale down the storage size
- You can NOT decrease the allocated storage for an RDS instance
> You can scale storage and also change storage type for all supported DB engines, except MSSQL server

## Scaling
> You can scale (Up only, not down) the compute and storage capacity of your existing RDS DB instances

> Scaling storage can happen while the RDS instance is still running, available/accessible
- This may cause some performance degradations during the change, but will result in enhanced I/O after

> Scaling compute will cause a downtime to DB instance

> You do the required scaling changes, then you can
- Immediately have the changes take effect ,
OR
- Leave it to the default, which will make the changes take effect during thế Maintenance window

## Scaling – MS SQL Server
> You can NOT change the storage capacity nor type of storage of the MS SQL Server on windows-based RDS instances
- This is due to extensibility limitations of striped storage attached to windows server

> To work around the above, you can take a snapshot, use it to start a new DB instance with the desired Storage type and capacity (must be an increase, not a decrease)
- Note that a new instance, will have a new RDS endpoint

## Scaling beyond RDS instance capabilities
> If you hit the largest RDS DB instance, and you still need to scale, you can;
- Use partitioning and split your RDS DB over multiple RDS instances
=======================================
########## AWS RDS SECURITY ########### 

> AWS provides multiple features to provide RDS security: 

1. DB instance can be hosted in a VPC for the greatest possible network access control
2. IAM policies can be used to assign permissions that determine who is allowed to manage RDS resources
3. Security groups allow to control what IP addresses or EC2 instances can connect to the databases on a DB instance
4. Secure Socket Layer (SSL) connections with DB instances
5. RDS encryption to secure RDS instances and snapshots at rest.
6. Network encryption and transparent data encryption (TDE) with Oracle DB instances

=======================================
############# AWS Aurora ##############

> It is a fully managed relational database engine that's compatible with MySQL and PostgreSQL.

> It can deliver up to five times the throughput of MySQL and up to three times the throughput of PostgreSQL 
- at a price one-tenth of that Commercial databases while delivering similar performance and availability.

##### Aurora Scaling #####
> The underlying storage grows automatically as needed, up to 64 tebibytes (TiB)
-  A tebibyte equals nearly 1.1 TB

> Compute resources can scale up to 64 vCPUs and 488 GB of memory.

> It maintains 2 copies of data in each AZ, with a minimum of three AZ. 
- Therefore, we can say that it maintains 6 copies of your data.

##### Replicas #######
> There are 2 types of Replicas:
1. Aurora Replicas(up to 15 Aurora Replicas across AZs).
2. MySQL Read Replicas (up to 5 Read Replicas across Azs)
=======================================
############ AWS DynamoDB #############

> Amazon DynamoDB is a fast and flexible NOSQL DB service for all app that require consistent single-digit millisecond latency at any scale.
> It is a FULLY MANAGED DB that supports both document and key-value data models.

> Its flexible data model and performance makes it a great fit for mobile, web, gaming, ad-tech, IOT, and many other applications.

> It is stored in SSD storage.
> It is normally used in conjuction with S3. 
- Ex- after storing image in S3, we can store their metadata in DynamoDB. We can also create 2nrd index for DynamoDB Table.

>> The maximum size of a DynamoDB item is 400KB
> It stores data indexed by a primary key
> It is spread across 3 geographically data centres

> When interacting with DynamoDB directly, there is a short list of header attributes that are required :
x-Amz-Target : operation name like GetIten
X-amz-date
host
content-type

> DynamoDB Auto Scaling uses AWS app AS to dynamically adjust provisioned throughput capacity in response of actual traffic 
- This help to automate capacity management of tables and global secondary indexes. 
- we simply specify the desired target utilization and provide upper and lower bounds for read and write capacity.
- will be on by default for all new tables and indexes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Because of its availability in 3 geographically DC, It consists of 2 different types of consistency models:

1. Eventual Consistent Reads
2. Strongly Consistent Reads

## AWS DynamoDB Throughput Capacity
> DynamoDB throughput capacity depends on the read/write capacity modes for performing read/write operation on tables.

> There are 2 types of read/write capacity modes:
1. Provisioned mode
2. On-demand mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
###### 1. PROVISIONED MODE ######
> It defines the maximum amount of capacity that an application can use from a specified table.

> In a provisioned mode, we need to specify the number of reads and writes per second required by the app.

> If the limit of Provisioned mode throughput capacity is exceeded, then this leads to the request throttling.

> A provisioned mode is GOOD FOR APP THAT HAVE PREDICTABLE AND CONSISTENT TRAFFIC.

> The Provisioned mode consists of 2 capacity units:
1. Read Capacity unit
2. Write Capacity unit

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##### 1a. READ CAPACITY UNIT #####

> The total number of read capacity units depends on the item size, and read consistency model.

> Read Capacity unit represents 2 types of consistency models:
1. Strongly Consistent model 
2. Eventually Consistent model

> 1 Read Capacity Unit = 1 Strong consistent OR 2 eventually consistent reads per second for an item up to 4KB in size.

> DynamoDB will require additional read capacity units when an item size is greater than 4KB. 
- For example, if the size of an item is 8KB, 2 read capacity units are required for strongly consistent read while 1 read capacity unit is required for eventually consistent read.
---------------------------------
#### 1b. WRITE CAPACITY UNIT ####

> The total number of write capacity unit depends on the item size.

> Only 1 write capacity unit is required for an item up to size 1KB.

> DynamoDB will require additional write capacity units when size is greater than 1KB. 
- For example, if an item size is 2KB, two write capacity units are required to perform 1 write per second.
- For example, if you create a table with 20 write capacity units, then you can perform 20 writes per second for an item up to 1KB in size.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
###### 2. ON-DEMAND MODE ########
> DynamoDB on-demand mode has a flexible new billing option which is capable of serving thousands of requests per second without any capacity planning.

> On-Demand mode offers 'pay-per-request' pricing for read and write requests 
- so that you need to pay only for what you use, thus, making it easy to balance costs and performance.

> In On-Demand mode, DynamoDb accommodates the customer's workload instantly as the traffic level increases or decreases.

> On-Demand mode supports all the DynamoDB features such as encryption, point-in-time recovery, etc 
- IT DOESN'T SUPPORT AUTO-SCALING

> If you do not perform any read/write, then you just need to pay for data storage only.

> On-Demand mode is useful for those applications that have unpredictable traffic and database is very complex to forecast.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
########## SCALABILITY ##########
> It provides push button scaling where we can increase the read/write throughput without downtime or performance degradations

> we can scale provisioned capacity of DynamoDB table anytime 
> we can scale down provisioned capacity only 4 time during day. 
=======================================
############ AWS Redshift #############

> Redshift is a fast and powerful, fully managed, petabyte-scale data warehouse service

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
### BENEFITS ###

> Query our Data Lake:
- can directly query open data formats stored in S3 with Redshift spectrum(a feature of Redshift without need for unnecessary data movement)

> Secure
- It can be encrypted with AWS KMS or HSM

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### USE CASES ####
> Accelerated analytics workload 
> Unified data warehouse and data lake 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> AWS Documentation mentions the following on monitoring Redshift Clusters:

> Amazon CloudWatch metrics help to monitor the physical aspects of cluster, such as CPU utilization, latency, and throughput. 
- Metric data is displayed directly in the Redshift console. 
- we can also view it in CloudWatch console, or 
- we can consume it in any other way such as with CloudWatch CLI OR SDKs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

> Regardless of whether we enable automated snapshots, we can take a manual snapshot whenever we want at any time. 
- By default, manual snapshots are retained indefinitely, even after we delete cluster. 
- we can specify the retention period when we create manual snapshot or we can change the retention period by modifying the snapshot. 
- If you create a snapshot using Redshift console, it defaults the snapshot retention period to 365 days.

> Automated snapshots are automatically deleted within the period of 1(Least) to 35(Max) days (Based on the retention period settings). 

> So we have to take care of the Manual snapshots instead of Automated snapshots. 
- Amazon Redshift never deletes Manual snaphots automatically, like how it does for Automatic Snapshots.

#### REDSHIFT CONFIGURATION ####
> Redshift consists of two types of nodes:

1. Single node: 
- A single node stores up to 160 GB.

2. Multi-node: 
> It is a node that consists of more than one node. 
> It is of two types:

2a. LEADER NODE
> IT MANAGES THE CLIENT CONNECTIONS AND RECEIVES QUERIES. 
> A leader node receives the queries from the client applications, parses the queries, and develops the execution plans. 
- It coordinates with the parallel execution of these plans with the compute node and combines the intermediate results of all the nodes, and then return the final result to the client application.

2b. COMPUTE NODE
> A compute node executes the execution plans, and then intermediate results are sent to the leader node for aggregation before sending back to the client application. 
- It can have up to 128 compute nodes in a cluster
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##### REDSHIFT – PERFORMANCE ####
1. Columnar Data Storage:
- Instead of storing data as series of rows, Amazon Redshift organizes the data by column.
- Unlike Row-based systems, which are ideal for transaction processing's, column-based systems are ideal for data warehousing and analytics, where queries often involve aggregates performed over large data sets.
- Since only the columns involved in the queries are processed and columnar data is stored sequentially on the storage media, column-based systems require far few I/Os, greatly improving query performance.

## Advanced Compression:
- Columnar data stores can be compressed much more than row-based data stores.
- Amazon Redshift employs multiple compression techniques and can often achieve significant compression relative to traditional relational data stores.
- When loading data into an empty table, Amazon Redshift automatically samples your data and selects the most appropriate compression technique.

• Massively Parallel processing (MPP):
- Amazon Redshift automatically distributes data and query load across all nodes.
- Redshift makes it easy to add nodes to data warehouse and enables you to maintain fast query performance as data warehouse grows.

## Redshift – Security
> Encrypted in transit using SSL
> Encrypted at rest using AES-256 encryption
> By Default, Redshift takes care of key management.
> Manage your own keys through HSM
> AWS Key Management Service

## Redshift – Backup Retention
> Amazon Redshift automaticallly patches and backup (snapshots) your data warehouse, storing the backups for a user-defined Retention period in AWS S3.
> It keeps the backup by default for 1 day (24 hours) but you can configure it from 0-35 days.
> Automatic backups are stopped if you choose retention period of 0
> You have access to these automatic snapshots during the retention period.
> If you delete the cluster, your automatic snapshots are deleted as well.
> Manual backups are not deleted automatically, if you not delete them manually, you will be charged standard S3 storage rates.

##Redshift – Restore
Amazon Redshift currently supports only one AZ (no Multi-AZ option)
• You can restore from your backup to a new Redshift cluster in the same
or different AZ

## Redshift – Monitoring
> Metrics for compute utilization, storage utilization and read/write traffic to your Amazon Redshift data warehouse cluster, are available free of charge via AWS Cloudwatch.
> You can also add additional user-defined, metrics via AWS Cloudwatch custom metric functionality.

## Q: An organization is managing a Redshift cluster in AWS. They need to monitor the performance of this Redshift cluster to ensure that it is performing as efficiently as possible. Which of the following services can be used for achieving this requirement? Please select:
A) Cloudtrail
B) VPC Flowlogs
C) Cloudwatch
D) AWS Trusted advisor

## Q : A company needs to have a columnar structured database storage suitable to perform complex analytics queries against petabyte of structured data, Which of the following can meet this requirement? Please select:
A) Amazon RDS
B) Redshift
C) Elasticache
D) DynamoDB

## Q: There is a requirement to load a lot of data from your on-premises network to AWS Redshift. Which of the below options can be used for data transfer? Please select two possible answers

A) Direct Connect
B) Snowball
C) AWS VPN
D) Can't transfer huge amount of data to AWS
=======================================
########## Amazon ElastiCache #########

> Amazon ElastiCache makes it easy to set up, manage, and scale distributed in-memory cache environments

> It is AWS fully managed Web service.
> It is an in-memory key-value data store engine in the cloud and provide ultra-fast (sub-millisecond latency) and inexpensive access to copies of data.
> It improves the performance of web applications by allowing for the retrieval of information from a fast, managed, in-memory system (instead of reading it from the DB itself)

> Improves response times for user transactions and queries
> Can enhance response time for read-intensive And/or compute- intensive workloads.
> It offloads the read workload from the main DB instances
> It does this by storing the results of frequently accessed pieces of data in-memory

> ElastiCache is used in between WebServer and Database to store cache. WebServer might response through cache if the request match.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## FEATURE ##
> Automatic detection of and recovery from cache node failures.
> Flexible AZ placement of nodes and clusters.
> Integration with other AWS services such as EC2, CloudWatch, CloudTrail, and SNS to provide a secure, high-performance, managed in-memory caching solution.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ElastiCache Supports 2 Caching engines:
1. Memcached (its not a data store (DB), only cache )
2. Redis (is the fast NOSQL – can be used as database)

### 1. ElastiCache - Memcached ##
> Elasticache is not persistent
> Can not be used as a data store
> Ideal front-end for data stores (RDS, DynamoDB)
> Use Cases:
- cache contents of a DB
- cache data from dynamically generated webpages
- Transient session data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### 2. Elasticache - Redis #####
> Redis is persistent
> It is the fast NoSQL engine 
> It can be used as a data store.

> Use cases:
- Web
- Mobile Apps
- Financial Apps
- Gaming
- Ad-tech
- IoT
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Elasticache Exam Tip
• Typically you will be given a scenario where a particular database is under a lot of stress/load. You may be asked which service you should use to alleviate this.
>>> Elasticache is a good choice if your database is particularly read heavy and not prone to frequent changing,