=======================================
######### AWS ANALYTICS SERVICES ######

#### AWS KINESIS 
> It is a platform on AWS that sends your STREAMING DATA. 
- It makes it easy to analyze load streaming data and also provides the ability for you to build custom applications based on your business needs.

## AWS Athena
> It is a SERVERLESS PLATFORM which can be USED TO ANALYZE COST & USAGE REPORTS uploaded in S3 buckets. 
- Using Athena, a customized query can be requested using standard SQL.

## AWS Glue
- It is fully managed ETL service (Extract, Transform and Load) that makes it easy for customer to prepare 	and load their data for analytics

## AWS CloudSearch 
## ElasticSearch 
## AWS EMR (Elastic MapReduce)
## AWS Data Pipeline 
=======================================
############ AWS KINESIS ##############

> we can use Amazon Kinesis Data Streams to collect and PROCESS LARGE STREAMS OF DATA RECORDS IN REAL TIME. 
- it is a collection of services for processing streams of various data.

> Data is processed in “shards” – with each shard able to ingest 1000 records per second.
- There is a default limit of 500 shards, but you can request an increase to unlimited shards.

> A record consists of a partition key, sequence number, and data blob (up to 1 MB).

> Transient data store – DEFAULT RETENTION OF 24 HOURS, but can be configured for upto 7days.

> There are 4 types of Kinesis service 
1. Kinesis Video Streams 
- securely process video stream for analytics, ML etc
- support encryption at rest with KMS

2. Kinesis Data Streams
- It can process stream of big data
- we can create data-processing app using this service
- it can stores data for later processing (key diff with Firehose)
- Kinesis Data Streams replicates synchronously across three AZs.

- it has set of shards that has a SEQUENCE OF DATA RECORDS, and each data record has a sequence number that is assigned by Kinesis Data Streams. 
- Kinesis can also easily handle the high volume of messages being sent to the service.
- it enables real-time processing of streaming big data
- It provides ordering of records, as well as the ability to read and/or replay records in the same order to multiple Kinesis Apps. 
- Kinesis Client Library (KCL) delivers all records for a given partition key to the same record processor, making it easier to build multiple apps reading from the same Kinesis data stream (for example, to perform counting, aggregation, and filtering).

- Data records are therefore STORED IN SHARDS in your stream temporarily.
- It stores records from 24hrs(by default) to 168hrs(max).

3. Kinesis Data Firehose(ETL)
- it Captures, transforms, and loads streaming data.
- Kinesis Data Streams can be used as the source(s) to Kinesis Data Firehose.
- it can batch, compress, and encrypt data before loading it.
- It can capture, transform, and load streaming data into S3, Redshift, Elasticsearch Service, and Splunk, enabling near real-time analytics
- NO SHARDS, TOTALLY AUTOMATED.

4. Kinesis Data Analytics
- it is the easiest way to process and analyze real-time, streaming data.
- Can use standard SQL queries to process Kinesis data streams.
- Can ingest data from Kinesis Streams and Kinesis Firehose.


> Kinesis streams can be used to analyze the data and can feed it using AWS EMR to the analytics-based database like RedShift which works on OLAP.

> Kinesis Firehose is used to ship the data to other AWS service, not for the analysis

> AWS Application Auto scaling can be used to automatically scale Kinesis Streams. 
- For this, CloudWatch can be used to monitor Kinesis Data Stream shard metrics. 
- Based on the changes in these metrics, CloudWatch can initiate a notification to Application Auto Scaling. 
- This will trigger an API Gateway to call Lambda Functions to increase/decrease the number of Kinesis Data Stream Shards based upon metric values.

=======================================
############ AWS ATHENA ##############
> It is an interactive query service that makes it EASY TO ANALYZE DATA IN S3 using standard SQL.
- it uses Presto with full standard SQL support and works with a variety of standard data formats, including CSV, JSON, ORC, Apache Parquet and Avro.
- it can also handle complex analysis, including large joins, window functions, and arrays.
- it uses a managed Data Catalog to store information and schemas about the databases and tables

> it is out-of-the-box integrated with AWS Glue Data Catalog, 
- which allowing you to create a unified metadata repository across various services, 
- crawl data sources to discover schemas and populate your Catalog with new and modified table and partition definitions, and maintain schema versioning.

> Amazon QuickSight will be useful for data visualization.

> AWS Athena pricing is based upon per query and the amount of data scanned in each query. 
- Below condition can lead to minimizing the amount of data scanned for each query, improving performance & reducing cost:-
- If data is partitioned based upon location & date  
- If a separate Workgroup can be created based upon users, teams, application or workloads. 

=======================================
############# AWS GLUE ################

> AWS Glue keeps a track of processed data using Job Bookmark. 
- Enabling Job Bookmark will help to scan only changes since the last bookmark and prevent the processing of whole data again. 
=======================================
########## AWS CloudSearch ############

> With this, you can quickly add rich search capabilities to website or application. 
- don't need to become a search expert or worry about hardware provisioning, setup, and maintenance. 
- Configure through AWS Console, we can create a search domain and upload the data that we want to make searchable, and 
- it will automatically provision the required resources and deploy a highly tuned search index. 
- we can easily change search parameters, fine-tune search relevance, and apply new settings at any time. 
- As your volume of data and traffic fluctuates, Amazon CloudSearch seamlessly scales to meet your needs. 

=======================================
############## AWS EMR ################

> It is a web service that enables businesses, researchers, data analysts, and developers to easily and cost-effectively process vast amounts of data.
- it utilizes a hosted Hadoop framework running on Amazon EC2 and Amazon S3.
- it also support Apache Spark, HBase, Presto and Flink

> Most commonly used for log analysis, financial analysis, or extract, translate and loading (ETL) activities.

> With EMR, you have ACCESS TO THE UNDERLYING OS

=======================================
######### AWS Data Pipeline ###########

> AWS Data Pipeline is a web service that you can USE TO AUTOMATE THE MOVEMENT AND TRANSFORMATION OF DATA. 
- With AWS Data Pipeline, you can define data-driven workflows, so that tasks can be dependent on the successful completion of previous tasks. 
- You define the parameters of your data transformations and AWS Data Pipeline enforces the logic that you've set up. 