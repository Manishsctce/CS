######### AWS STORAGE SERVICE #########

############### EBS ###################
############### EFS ###################
############ Amazon FSx ###############
=======================================
############### EBS ###################

## What two features are supported with EBS volume Snapshot feature?

A. EBS replication across regions
B. EBS multi-zone replication
C. EBS single region only
D. full snapshot data only
E. unencrypted snapshot only


Answer (A,B)

Explantion - > EBS volume are AZ specific 
- but snapshot are region specific

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## What is an EBS Snapshot?

A. backup of an EBS root volume and instance data
B. backup of an EC2 instance
C. backup of configuration settings
D. backup of instance store

Answer (A)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You terminate an EC2 instance and find that the EBS root volume that was attached to the instance was also deleted. How can you correct this?

A. You can’t. A root volume is always deleted when the EC2 instance attached to that volume is deleted.
B. Take a snapshot of the EBS volume while the EC2 instance is running. Then, when the EC2 instance is terminated, you can restore the EBS volume from the snapshot.

C. Remove termination protection from the EC2 instance.
D. Use the AWS CLS to change the DeleteOnTermination attribute for the EBS volume to “false.”


Answer: D. 

By default, EBS root volumes are terminated when the associated instance is terminated. However, this is only the default value; therefore A is not correct. Option B is not directly addressing the question; the EBS volume would still be deleted even if you take a snapshot. 
Option C is not relevant, but 
option D : use AWS CLI (or the console) to set the root volume to persist after instance termination.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## In what manner are EBS snapshots backed up to S3?

A. Via full backup according to the backup policy set on the volume
B. Incrementally
C. Synchronously
D. EBS volumes are not stored on S3.


Answer: B
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Can you attach an EBS volume to more than one EC2 instance at the same time?

A. Yes, as long as the volume is not the root volume.
B. No, EBS volumes cannot be attached to more than one instance at the same time.
C. Yes, as long as the volume is one of the SSD classes and not magnetic storage.
D. Yes, as long as at least one of the instances uses the volume as its root volume.


Answer: B

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## There is a requirement to host a database application having resource-intensive reads and writes (lots of reads and writes). Which of the below options would be the most suitable to meet this requirement? [WL145]

A. EBS Provisioned IOPS SSD
B. EBS SSD
C. EBS Throughput Optimized HDD
D. EBS Cold Storage


ANSWER : C
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## An application with a 150 GB relational database runs on an EC2 Instance. While the application is used infrequently with small peaks in the morning and evening, which storage type would be the most cost-effective option for the above requirement? [WL106]

A. Amazon EBS provisioned IOPS SSD
B. Amazon EBS Throughput Optimized HDD
C. Amazon EBS General Purpose SSD
D. Amazon EFS


ANSWER : C

EXPLANATION : 
Since the database is used infrequently, not throughout the day, and the question requires the MOST cost-effective storage type, the preferred choice would be EBS General Purpose SSD over EBS provisioned IOPS SSD.

The minimum volume of Throughput Optimized HDD is 500 GB. As per our scenario, we need 150 GB only. 
Hence, option C: Amazon EBS General Purpose SSD, would be the best choice for a cost-effective storage solution. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## An application with a 150 GB relational database runs on an EC2 Instance. This is a critical business application requiring more than 16,000 IOPS of throughput per volume. Which storage type would be preferred? [WL309]

A. Amazon EBS Provisioned IOPS SSD
B. Amazon EBS Throughput Optimized HDD
C. Amazon EBS General Purpose SSD
D. Amazon EFS


EXPLANATION:
Answer – A

 As per AWS documentation Provisioned IOPS (SSD) are used for applications that require high Inputs/Outputs Operations per sec and is mainly used in large databases such as Mongo, Cassandra, Microsoft SQL Server, MySQL, PostgreSQL, Oracle where as Throughput optimized HDD although it is cheaper compared to PIOPS is used for dataware houses where it is designed to work with throughput intensive workloads such as big data, log processing etc. 
So Option A is the right choice for this case. 
AWS Documentation mentions the following:

Provisioned IOPS SSD (io1) volumes are designed to meet the needs of I/O-intensive workloads, particularly database workloads that are sensitive to storage performance and consistency. 
Max IOPS**/Volume for 

EBS Provisioned IOPS SSD - 64,000
EBS General Purpose SSD - 16,000 
Throughput Optimized HDD - 500
Cold HDD - 250

For more information on AWS EBS Volumes, please visit the following URL:

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##38: A company has a High Performance Computing (HPC) cluster that is composed of EC2 Instances with Provisioned IOPS volume to process transaction-intensive, low-latency workloads. The Solutions Architect must maintain high IOPS while keeping the latency down by setting the optimal queue length for the volume. The size of each volume is 10 GiB.
Which of the following is the MOST suitable configuration that the Architect should set up? [UD438]

A. Set the IOPS to 400 then maintain a low queue length.
B. Set the IOPS to 600 then maintain a high queue length.
C. Set the IOPS to 500 then maintain a low queue length.
D. Set the IOPS to 800 then maintain a low queue length.


EXPLANATION : EBS Type
ANSWER : C

> Provisioned IOPS SSD (io1) volumes are designed to meet the needs of I/O-intensive workloads, particularly database workloads, that are sensitive to storage performance and consistency. 
- Unlike gp2, which uses a bucket and credit model to calculate performance, an io1 volume allows you to specify a consistent IOPS rate when you create the volume, and Amazon EBS delivers within 10 percent of the provisioned IOPS performance 99.9 percent of the time over a given year.

An io1 volume can range in size from 4 GiB to 16 TiB. You can provision from 100 IOPS up to 64,000 IOPS per volume on Nitro system instance families and up to 32,000 on other instance families. The maximum ratio of provisioned IOPS to requested volume size (in GiB) is 50:1.

For example, a 100 GiB volume can be provisioned with up to 5,000 IOPS. On a supported instance type, any volume 1,280 GiB in size or greater allows provisioning up to the 64,000 IOPS maximum (50 × 1,280 GiB = 64,000).


An io1 volume provisioned with up to 32,000 IOPS supports a maximum I/O size of 256 KiB and yields as much as 500 MiB/s of throughput. 
- With the I/O size at the maximum, peak throughput is reached at 2,000 IOPS. A volume provisioned with more than 32,000 IOPS (up to the cap of 64,000 IOPS) supports a maximum I/O size of 16 KiB and yields as much as 1,000 MiB/s of throughput.

> The volume queue length is the number of pending I/O requests for a device. 
- Latency is the true end-to-end client time of an I/O operation, in other words, the time elapsed between sending an I/O to EBS and receiving an acknowledgement from EBS that the I/O read or write is complete. 
- Queue length must be correctly calibrated with I/O size and latency to avoid creating bottlenecks either on the guest operating system or on the network link to EBS.

- Optimal queue length varies for each workload, depending on your particular application's sensitivity to IOPS and latency. 
- If your workload is not delivering enough I/O requests to fully use the performance available to your EBS volume then your volume might not deliver the IOPS or throughput that you have provisioned.

- Transaction-intensive applications are sensitive to increased I/O latency and are well-suited for SSD-backed io1 and gp2 volumes. 
- You can maintain high IOPS while keeping latency down by maintaining a low queue length and a high number of IOPS available to the volume.
- Consistently driving more IOPS to a volume than it has available can cause increased I/O latency.

Throughput-intensive applications are less sensitive to increased I/O latency, and are well-suited for HDD-backed st1 and sc1 volumes. You can maintain high throughput to HDD-backed volumes by maintaining a high queue length when performing large, sequential I/O.

Therefore, for instance, a 10 GiB volume can be provisioned with up to 500 IOPS. Any volume 640 GiB in size or greater allows provisioning up to a maximum of 32,000 IOPS (50 × 640 GiB = 32,000). Hence, the correct answer is to set the IOPS to 500 then maintain a low queue length.

Setting the IOPS to 400 then maintaining a low queue length is incorrect because although a value of 400 is an acceptable value, it is not the maximum value for the IOPS. You will not fully utilize the available IOPS that the volume can offer if you just set it to 400.

The options that say: Set the IOPS to 600 then maintain a high queue length and Set the IOPS to 800 then maintain a low queue length are both incorrect because the maximum IOPS for the 10 GiB volume is only 500. Therefore, any value greater than the maximum amount, such as 600 or 800, is wrong. Moreover, you should keep the latency down by maintaining a low queue length, and not higher.


References:
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html


Check out this Amazon EBS Cheat Sheet:
https://tutorialsdojo.com/aws-cheat-sheet-amazon-ebs/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## The security policy of an organization requires an application to encrypt data before writing to the disk. Which solution should the organization use to meet this requirement? [WL118]

A. AWS KMS API
B. AWS Certificate Manager
C. API Gateway with STS
D. IAM Access Key

ANSWER : A

EXPLANATION : 
Option B is incorrect. The AWS Certificate Manager can be used to generate SSL certificates to encrypt traffic in transit, but not at rest.

Option C is incorrect. It is used for issuing tokens while using the API gateway for traffic in transit.

Option D is used for providing secure access to EC2 Instances.

AWS Documentation mentions the following on AWS KMS:

AWS Key Management Service (AWS KMS) is a managed service that makes it easy for you to create and control the encryption keys used to encrypt your data. AWS KMS is integrated with other AWS services including Amazon Elastic Block Store (Amazon EBS), Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon Elastic Transcoder, Amazon WorkMail, Amazon Relational Database Service (Amazon RDS), and others to make it simple to encrypt your data with encryption keys that you manage.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## An application currently stores all its data on Amazon EBS Volumes. All EBS volumes must be backed up durably across multiple Availability Zones. 
What is the MOST resilient and cost-effective way to back up the volumes? [WL119]

A. Take regular EBS snapshots.
B. Enable EBS volume encryption.
C. Create a script to copy data to an EC2 Instance store.
D. Mirror data across 2 EBS volumes. 

ANSWER : A

EXPLANATION : 
Option B is incorrect because it does not help the durability of EBS Volumes.

Option C is incorrect since EC2 Instance stores are not durable.

Option D is incorrect since mirroring data across EBS volumes is inefficient in comparison with the existing option for EBS snapshots.

AWS Documentation mentions the following on AWS EBS Snapshots:

You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are incremental backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved. This minimizes the time required to create the snapshot and saves on storage costs by not duplicating data. When you delete a snapshot, only the data unique to that snapshot is removed. Each snapshot contains all of the information required to restore your data (from the moment when the snapshot was taken) to a new EBS volume.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## There is a requirement to host a database on an EC2 Instance. It is also required that the EBS volume should support 18,000 IOPS. 
Which Amazon EBS volume type would meet the performance requirements of this database? [WL129]

A. EBS Provisioned IOPS SSD
B. EBS Throughput Optimized HDD
C. EBS General Purpose SSD
D. EBS Cold HDD

ANSWER : A

EXPLANATION : 
For high performance and high IOPS requirements, as in this case, the ideal choice would be to choose EBS Provisioned IOPS SSD.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You work for a company that has a set of EC2 Instances. There is an internal requirement to create another instance in another availability zone. One of the EBS volumes from the current instance needs to be moved from one of the older instances to the new instance. How can you achieve this? [WL602]

A. Detach the volume and attach to an EC2 instance in another AZ.
B. Create a new volume in the other AZ and specify the current volume as the source.
C. Create a snapshot of the volume and then create a volume from the snapshot in the other AZ
D. Create a new volume in the AZ and do a disk copy of contents from one volume to another. 


EXPLANATION: 
Answer – C

> In order for a volume to be available in another availability zone, you need to first create a snapshot from the volume. Then in the snapshot from creating a volume from the snapshot , you can then specify the new availability zone accordingly. 

Option A is invalid, because the Instance and Volume have to be in the same AZ in order for it to be attached to the instance

Option B is invalid , because there is no way to specify a volume as a source

Option D is invalid , because the Diskcopy would just be a tedious process. 
For more information on snapshots, please visit the below URL

http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html
 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You have a set of EC2 Instances that support an application. They are currently hosted in the US Region. In the event of a disaster, you need a way to ensure that you can quickly provision the resources in another region. How could this be accomplished? [WL322] (SELECT TWO)

A. Copy the underlying EBS Volumes to the destination region. 
B. Create EBS Snapshots and then copy them to the destination region. 
C. Create AMIs for the underlying instances and copy them to the destination region. 
D. Copy the metadata for the EC2 Instances to S3. 


EXPLANATION:
Correct Answers – B and C

Snapshots can be used to create a AMI or template of the underlying instance. You can then copy the AMI to another region. You can also make snapshots of the volumes and then copy them to the destination region. 
For more information on AMIs and EBS Snapshots, please visit the following URLs:

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are building an automated transcription service in which Amazon EC2 worker instances process an uploaded audio file and generate a text file. You must store both of these files in the same durable storage until the text file is retrieved. You do not know about the storage capacity requirements. Which storage option would be both cost-efficient and scalable in this situation? [WL324]

A. Multiple Amazon EBS Volume with snapshots
B. A single Amazon Glacier Vault
C. A single Amazon S3 bucket
D. Multiple instance stores


EXPLANATION:
Correct Answer – C

Amazon S3 is the perfect storage solution for audio and text files. It is a highly available and durable storage device. 
For more information on Amazon S3, please visit the following URL:

https://aws.amazon.com/s3/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
### 15:WL6: You are working as an AWS Architect for a retail company using AWS EC2 instance for a web application. Company is using Provisioned IOPS SSD EBS volumes to store all product database. 
This is a critical database & you need to ensure appropriate backups are accomplished every 12 hours. Also, you need to ensure that storage space is optimally used for storing all these snapshots removing all older files. Which of the following can help to meet this requirement with least management overhead? [WL615]

A. Manually create snapshots & delete old snapshots for EBS volumes as this is a critical data.
B. Use Amazon CloudWatch events to initiate AWS Lambda which will create snapshot of EBS volumes along with deletion of old snapshots.
C. Use Amazon Data Lifecycle Manager to schedule EBS snapshots and delete old snapshots as per retention policy.
D. Use Third party tool to create snapshot of EBS volumes along with deletion of old snapshots. 


EXPLANATION: EBS
Correct Answer – C

> Amazon Data Lifecycle Manager can be used for creation, retention & deletion of EBS snapshots. 
- It protects critical data by initiating backup of Amazon EBS volumes at selected intervals , along with storing & deletion of old snapshots to save storage space & cost. 

Option A is incorrect as this will result in additional admin work & there can be risk of losing critical data due to manual errors. 
Option B is incorrect as for this we will need to additional config changes in CloudWatch & AWS Lambda. 
Option D is incorrect as this will result in additional cost to maintain a third-party software. 

For more information on Automating Amazon EBS Snapshot Lifecycle, refer to following URL,
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 

 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following statements are correct with respect to instance store and EBS volume? Please select 2 correct options. [WL_EBS1]

A. Instance store backed EC2 instances will persist storage across instance stop, terminate and failures.

B. EBS backed EC2 instances can persist storage across instance stop, terminate and failures.

C. Instance store backed EC2 instance will persist storage only during instance stop and start.
D. You cannot add instance store volumes once EC2 instance is launched.
E. All available EC2 instance types support instance store and EBS volumes.


Answer : B, D
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Your organization is planning to build a BigData project on AWS. They need high data transfer rates for huge workloads to stream through with better performance. They are also looking for a solution which is cost effective. Which EBS storage type would you choose in this scenario?

A. General Purpose SSD
B. Provisioned IOPS SSD
C. Throughput Optimized HDD
D. Cold HDD


Answer : C

Explanation : 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are working for a data management company which uses AWS platform to manage the data for various customers. They are using AWS EBS backed EC2 instance with “Delete EBS volume on termination” checked. EC2 instances are used to run data streaming application which generates logs and are stored on EBS volumes. The log files are critical for auditing purposes. How would you protect the data stored on EBS volumes from accidental terminations of EC2 instances?

A. Every EBS volume will have a daily EBS snapshot created automatically by AWS.

B. Setup a Data LifeCycle Manager policy scheduler to create EBS snapshots for your EBS volumes.

C. When EC2 instance is terminated, it automatically creates a snapshot of EBS volume and then deletes the EBS volume.

D. Write a custom script on your EC2 instance and schedule it to back up the data onto AWS S3.


Answer: B

Explanation : 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following is an action you cannot perform on an EBS snapshot?

A. Create Image from snapshot.
B. Create EBS volume from snapshot.
C. Share a snapshot with another AWS account.
D. Make unencrypted copy of an encrypted snapshot.


Answer : D

Explanation : 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are working as an AWS architect in your organization. An application is being developed on AWS EC2 instance and would need a local volume with low latency to handle database workloads. They figured out Provisioned IOPS SSD volume type suits best. However, when the application team is launching an EC2 instance, they found an option named “EBS-optimized”. They reached out to you asking the purpose of EBS optimized instances. What do you suggest?


A. Amazon EBS–optimized instance provides additional, dedicated capacity for Amazon EBS I/O.
B. Amazon EBS-optimized instance comes with instance store ephemeral storage which provides
faster throughput.
C. EBS-optimized is a configuration on the EBS volume, not an option on EC2 instance
D. Amazon EBS-optimized instances cannot have provisioned IOPS SSD vol. types. They only work with General Purpose SSD, throughput optimized HDD, cold HDD
Answer : 

Explanation : 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 

=======================================
############### EFS ###################

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are building a content serving web application with 20 EC2 instances load balanced. For all the instances, content storage remains the same. You have chosen AWS EFS to act as common storage repository. Your application need to have as low latency as possible when serving content to the web users. Which of the following option would you choose and why? [WL864]

A. Performance mode = General Purpose, AWS can handle performance with general purpose mode till 10s of EC2 instances.
B. Performance mode = General Purpose, provides low-latency access to EFS.
C. Performande mode = Max I/O, provides better performance when sharing EFS across more than 10 EC2 instances.
D. Performance mode = Max I/O, provides low-latency access to EFS. 


EXPLANATION: EFS
Answer: B

 Although Max I/O is recommended to be used when tens, hundreds or thousands of EC2 instances sharing same EFS, it can slightly increase the latency. In this case, the question states the latency need to be as low as possible. 

Performance Modes
To support a wide variety of cloud storage workloads, Amazon EFS offers two performance modes. You select a file system's performance mode when you create it. 
The two performance modes have no additional costs, so your Amazon EFS file system is billed and metered the same, regardless of your performance mode. For information about file system limits, see Limits for Amazon EFS File Systems. 
Note

An Amazon EFS file system's performance mode can't be changed after the file system has been created. 
General Purpose Performance Mode
We recommend the General Purpose performance mode for the majority of your Amazon EFS file systems. General Purpose is ideal for latency-sensitive use cases, like web serving environments, content management systems, home directories, and general file serving. If you don't choose a performance mode when you create your file system, Amazon EFS selects the General Purpose mode for you by default. 
Max I/O Performance Mode
File systems in the Max I/O mode can scale to higher levels of aggregate throughput and operations per second with a tradeoff of slightly higher latencies for file operations. Highly parallelized applications and workloads, such as big data analysis, media processing, and genomics analysis, can benefit from this mode.  

https://docs.aws.amazon.com/efs/latest/ug/performance.html#performancemodes
 

 From above explanation, only option B is a correct statement
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are building a content serving web application on 5 EC2 instances load balanced. Total content size stored may not exceed 25 GB. You have chosen EFS for content storage. The content is accessed frequently by large number of users. Which throughput mode would you choose inorder to make sure that application on EC2 instances to EFS data transfer will not have performance bottleneck? [WL865]

A. Throughput mode = Bursting, provides a consistent high throughput for smaller data sizes.
B. Throughput mode = Bursting, automatically bursts throughput based on the requests irrespective of EFS data size
C. Throughput mode = Provisioned, you can configure specific throughput irrespective of EFS data size.
D. Throughput mode = Provisioned, AWS provisions high throughput for smaller data sizes and vice versa. 


EXPLANATION: EFS
Answer: C

> With Bursting Throughput mode, throughput on Amazon EFS scales as a file system grows. 

In this case, data size is 25 GB can burst through 100 MiB/s only for 18 mins/day. 
- Rest of the day, it uses baseline aggregate throughput and gives 1.25 MiB/s throughput. The baseline rate is 50

MiB/s per TiB of storage (equivalently, 50 KiB/s per GiB of storage). 
 

Specifying Throughput with Provisioned Mode
"Provisioned Throughput mode is available for applications with high throughput to storage (MiB/s per TiB) ratios, or with requirements greater than those allowed by the Bursting Throughput mode. 
- For example, say you're using Amazon EFS for development tools, web serving, or content management applications where the amount of data in your file system is low relative to throughput demands. Your file system can now get the high levels of throughput your applications require without having to pad your file system".  

https://docs.aws.amazon.com/efs/latest/ug/performance.html#throughput-modes
 
For this case, since the data is low compared to the throughput demand, provisioned mode is the right choice for throughput mode.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


EXPLANATION : 
ANSWER : 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


EXPLANATION : 
ANSWER : 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


EXPLANATION : 
ANSWER : 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


EXPLANATION : 
ANSWER : 

=======================================
############ Amazon FSx ###############

## A solutions architect needs to design a managed storage solution for a company"™s application that includes high-performance machine learning. This application runs on AWS Fargate, and the connected storage needs to have concurrent access to files and deliver high performance.
Which storage option should the solutions architect recommend?

A. Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3.
B. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.
C. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS.
D. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon EBS.


EXPLANATION : 
ANSWER : B
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 19 A high-performance file system is required for a financial modelling application. The data set will be stored on Amazon S3 and the storage solution must have seamless integration so objects can be accessed as files.
Which storage solution should be used? [DC19]

A. Amazon FSx for Windows File Server
B. Amazon FSx for Lustre
C. Amazon Elastic File System (EFS)
D. Amazon Elastic Block Store (EBS)


EXPLANATION :
ANSWER : B
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##52:UD6: A company is planning to deploy a High Performance Computing (HPC) cluster in its VPC that requires a scalable, high-performance file system. The storage service must be optimized for efficient workload processing, and the data must be accessible via a fast and scalable file system interface. It should also work natively with Amazon S3 that enables you to easily process your S3 data with a high-performance POSIX interface.
Which of the following is the MOST suitable service that you should use for this scenario?

A. Amazon Elastic File System (EFS)
B. Amazon FSx for Windows File Server
C. Amazon FSx for Lustre
D. Amazon Elastic Block Storage (EBS)

EXPLANATION : 
ANSWER : C

Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA). These workloads commonly require data to be presented via a fast and scalable file system interface, and typically have data sets stored on long-term data stores like Amazon S3.

Operating high-performance file systems typically require specialized expertise and administrative overhead, requiring you to provision storage servers and tune complex performance parameters. With Amazon FSx, you can launch and run a file system that provides sub-millisecond access to your data and allows you to read and write data at speeds of up to hundreds of gigabytes per second of throughput and millions of IOPS.

> Amazon FSx for Lustre works natively with Amazon S3, making it easy for you to process cloud data sets with high-performance file systems. 
- When linked to an S3 bucket, an FSx for Lustre file system transparently presents S3 objects as files and allows you to write results back to S3.
- You can also use FSx for Lustre as a standalone high-performance file system to burst your workloads from on-premises to the cloud. 
- By copying on-premises data to an FSx for Lustre file system, you can make that data available for fast processing by compute instances running on AWS. 
- With Amazon FSx, you pay for only the resources you use. 
- There are no minimum commitments, upfront hardware or software costs, or additional fees.

For Windows-based applications, Amazon FSx provides fully managed Windows file servers with features and performance optimized for "lift-and-shift" business-critical application workloads including home directories (user shares), media workflows, and ERP applications. It is accessible from Windows and Linux instances via the SMB protocol. If you have Linux-based applications, Amazon EFS is a cloud-native fully managed file system that provides simple, scalable, elastic file storage accessible from Linux instances via the NFS protocol.

For compute-intensive and fast processing workloads, like high-performance computing (HPC), machine learning, EDA, and media processing, Amazon FSx for Lustre, provides a file system that’s optimized for performance, with input and output stored on Amazon S3.

Hence, the correct answer is: Amazon FSx for Lustre.

Amazon Elastic File System (EFS) is incorrect because although the EFS service can be used for HPC applications, it doesn't natively work with Amazon S3. It doesn't have the capability to easily process your S3 data with a high-performance POSIX interface, unlike Amazon FSx for Lustre.

Amazon FSx for Windows File Server is incorrect because although this service is a type of Amazon FSx, it does not work natively with Amazon S3. This service is a fully managed native Microsoft Windows file system that is primarily used for your Windows-based applications that require shared file storage to AWS.

Amazon Elastic Block Storage (EBS) is incorrect because this service is not a scalable, high-performance file system.

References:
https://aws.amazon.com/fsx/lustre/
https://aws.amazon.com/getting-started/use-cases/hpc/3/

Check out this Amazon FSx Cheat Sheet:
https://tutorialsdojo.com/aws-cheat-sheet-amazon-fsx/
