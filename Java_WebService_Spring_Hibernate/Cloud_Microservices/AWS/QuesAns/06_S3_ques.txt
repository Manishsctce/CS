=======================================
################ S3 ###################
############# Signed URL ##############
######### S3 BUCKET NAME/URL ##########
########### S3 ENCRYPTION #############
=======================================
################ S3 ###################

## A company offers its customers short-lived contests that require users to upload files in hopes of winning prizes. These contests can last up to two weeks, with unknown uploads and the resulting file analysis can last up to three months.
The company needs an economic, scalable object storage solution to hold its customers' files. The files will be accessed once and then deleted, and it requires immediate access. The best solution for this company is:

A. Amazon Glacier
B. Elastic File System
C. Amazon S3 Standard
D. Amazon S3 Standard Infrequent Accessed


Answer - D. 
S3 – IA for data that is accessed less frequently, but requires rapid access when needed

Amazon Glacier is for data archiving and can be accessed within minutes
Elastic File System is file storage, not object storage as required
S3 standard is for frequently accessed data, and less economical than S3 - IA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following statements regarding S3 storage classes is true?

A. The availability of S3 and S3-IA is the same.
B. The durability of S3 and S3-IA is the same.
C. The latency of S3 and Glacier is the same.
D. The latency of S3 is greater than that of Glacier.


Answer - B 
S3 and S3-IA have the same durability. S3 has 99.99 availability, while S3-IA has 99.9 availability. 
Glacier has much greater first-byte latency than S3, so both C and D are false.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## A small business specializing in video processing wants to prototype cloud storage in order to lower its costs. However, management is wary of storing its client files in the cloud rather than on premises. They are focused on cost savings and experimenting with the cloud at this time. What is the best solution for their prototype?

A. Install a VPN, set up an S3 bucket for their files created within the last month, and set up an additional S3-IA bucket for older files. Create a lifecycle policy in S3 to move files older than 30 days into the S3-IA bucket nightly.

B. Install an AWS storage gateway using stored volumes.
C. Set up a Direct Connect and back all local hard drives up to S3 over the Direct Connect nightly.
D. Install an AWS storage gateway using cached volumes.

Answer - B 

> Anytime the primary consideration is storage with a local data presence—where data must be stored or seen to be stored locally—a storage gateway gives you the best
option. This reduces the choices to B and D. 
B will store the files in S3 and provide local cached copies, while D will store the files locally and push them to S3 as a backup. Since management is concerned about storage in the cloud of primary files, B is the best choice; local files are the primary source of data, while still allowing the company to experiment with cloud storage without “risking” its data being stored primarily in the cloud.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You have a group of web designers who frequently upload large zip files of images to S3, often in excess of 5 GB. Recently, team members have reported that they are receiving the error “Your proposed upload exceeds the maximum allowed object size.” What action should you take to resolve the upload problems?

A. Increase the maximum allowed object size in the target S3 bucket used by the web designers.
B. Ensure that your web designers are using applications or clients that take advantage of the Multipart Upload API for all uploaded objects.
C. Contact AWS and submit a ticket to have your default S3 bucket size raised; ensure that this is also applied to the target bucket for your web designers’ uploads.
D. Log in to the AWS console, select the S3 service, and locate your bucket. Edit the bucket properties and increase the maximum object size to 50 GB.

Many of these answers are nonsensical in terms of what AWS allows. The limits on size related to S3 are for objects; an individual object can be as large as 5 TB. Both A and C, then, are not useful (or possible). D proposes to increase the maximum object size to 50 GB, but the maximum object size is already 5 TB. Option B is correct; AWS recommends using Multipart Upload for all objects larger than 100 MB.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## For which of the following HTTP methods does S3 have eventual consistency? (Choose two.)
A. PUTs of new objects
B. UPDATEs
C. DELETEs
D. PUTs that overwrite existing objects

Answer : C, D. 
PUTs of new objects have a read after write consistency. DELETEs and overwrite
PUTs have eventual consistency across S3
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##  What is the smallest file size that can be stored on standard class S3?
A. 1 byte
B. 1 MB
C. 0 bytes
D. 1 KB

Answer : C. 

First, note that “on standard class S3” is a red herring, and irrelevant to the question.
Second, objects on S3 can be 0 bytes. This is equivalent to using touch on a file and then
uploading that 0-byte file to S3.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You’ve just created a new S3 bucket named ytmProfilePictures in the US East 2 region. You need the URL of the bucket for some programmatic access. What is the correct bucket URL?
A. https://s3-us-east-2.amazonaws.com/ytmProfilePictures
B. https://s3-east-2.amazonaws.com/ytmProfilePictures
C. https://s3-us-east-2-ytmProfilePictures.amazonaws.com/
D. https://amazonaws.s3-us-east-2.com/ytmProfilePictures

Answer : A. 

This is a matter of carefully looking at each URL. Bucket names—when not used as
a website—always come after the fully qualified domain name (FQDN); in other words,
after the forward slash. That eliminates C. Additionally, the region always comes earlier
in the FQDN than amazonaws.com, eliminating D. This leaves A and B. Of the two, A
correctly has the complete region, us-east-2.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You’ve just created a new S3 bucket named ytmProfilePictures in the US East 2 region and created a folder at the root level of the bucket called images/. You’ve turned on website hosting and asked your content team to upload images into the images/ folder. At what URL will these images be available through a web browser?

A. https://s3-us-east-2.amazonaws.com/ytmProfilePictures/images
B. https://s3-website-us-east-2.amazonaws.com/ytmProfilePictures/images
C. https://ytmProfilePictures.s3-website-us-east-2.amazonaws.com/images
D. https://ytmProfilePictures.s3-website.us-east-2.amazonaws.com/ytmProfilePictures/images

Answer : C. This is another question that is tricky unless you work through each part of the URL, piece by piece. 
The first clue is that this is a website hosted on S3, as opposed to directly accessing an S3 bucket. 
Where website hosting is concerned, the bucket name is part of the FQDN; where direct bucket access is concerned, the bucket name comes after the FQDN.
This is an essential distinction. This means that A and B are invalid. Then, you need to
recall that the s3-website portion of the FQDN is always connected to the region; in other
words, it is not a subdomain. The only option where this is the case is C.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following statements is not true?

A. Standard S3, S3-IA, and S3 One Zone-IA all are equally durable.
B. The availability of S3-IA and S3 One Zone-IA are identical.
C. Standard S3, S3-IA, and S3 One Zone-IA all have different availabilities.
D. S3 One Zone-IA is as durable as standard S3.

Answer : B. 

This is an important distinction when understanding S3 classes. 
Standard S3, S3-IA, and S3 One Zone-IA all are equally durable, although in One Zone-IA, data will be lost if the availability zone is destroyed. 
Each class has different availability, though: S3 is 99.99, S3-IA is 99.9, and S3 One Zone-IA is 99.5. Therefore, it is false that all have the same availability (B).
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following AWS services appear in the AWS console across all regions? (Choose two.)
A. S3
B. EC2
C. IAM
D. RDS

Answer : A, C. 

S3 buckets are created within a region, but the AWS console and your account will show you all S3 buckets at all times. 
While a bucket is created in a specific region, names of buckets are also global. 
IAM permissions are also global and affect all regions. 
RDS and EC2 instances are region specific, and only appear in the regions in which they were created in the AWS console.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You have spent several days of your last DevOps sprint building an AMI upon which all instances of your development team’s application should reside. The application will be deployed into multiple regions and interact with multiple S3 buckets, and you now need the new AMI in us-east-2 and us-west-2, in addition to us-east-1, where you created the AMI. How can you make the new AMI available in us-east-2 and us-west-2?

A. Copy the AMI from us-east-1 to us-east-2 and us-west-2. Launch the new instances using the copied AMI.

B. Ensure that all application instances share a security group. AMIs are available to all instances within a security group, regardless of the region in which the AMI was created.

C. You can immediately launch the AMI, as all AMIs appear in all regions through the AWS console.

D. Copy the AMI from us-east-1 to us-east-2 and us-west-2. Apply launch permissions and S3 bucket permissions and then launch new instances using the updated AMI.

Answer. D.
AMIs are not cross-region, regardless of account or security group. This makes B and C invalid. 
A is a valid choice but will not preserve any of the permissions or roles that allow the instance to connect to S3. 
Therefore, D is the correct option: manual configuration of the AMI after it has been copied is required for correct operation.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You have an S3 bucket and are working on cost estimates for your customer. She has asked you about pricing of objects stored in S3. There are currently objects in the buckets ranging from 0 bytes to over 1 GB. In this situation, what is the smallest file size that S3-IA will charge you for?

A. 1 byte
B. 1 MB
C. 0 bytes
D. 128 KB


Answer: D. 

While S3 allows for 0-byte objects, and charges as such, S3-IA charges all objects as if they are at least 128 KB in size. 
So while you can store a smaller object in S3-IA, it will be considered 128 KB for pricing and charging purposes.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following are valid criteria for determining which region to choose for your S3 buckets? (Choose two.)

A. The distance between the region and your user base
B. The distance between the region and your on-premises operations
C. The distance between the region and other regions in your AWS account
D. The distance between the region and your development team


Answer: A, B. 

Valid concerns in this list include placing storage close to your users, to reduce network latency, and distance from your operations center. 
This latter is a little less obvious but is centered around disaster recovery scenarios: If a disaster destroyed your operations center, you would not want your storage on AWS to be geographically in the same area.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following services is used at an on-premises site to connect to cloud-based storage?

A. Storage gateway
B. Virtual private gateway
C. Customer gateway
D. Virtual private network


Answer: A. 
A storage gateway is the correct answer, as it is used for caching or storing data and connecting to S3. A customer gateway is the anchor on the customer side of an Amazon VPN connection. A virtual private gateway is used for connecting into AWS via a VPN, and a virtual private network is actually what VPN stands for.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following are valid options for storage gateways? (Choose two.)

A. File gateway
B. Volume gateway
C. Cached gateway
D. Virtual private gateway


Answer: A, B. 

Both file and volume gateways offer solutions for connecting to cloud-based storage. A cached gateway isn’t an AWS option, and a virtual private gateway is used in creating VPN connections.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are tasked with recommending a storage solution for a large company with a capital investment in an NFS-based backup system. The company wants to investigate cloudbased storage but doesn’t want to lose its software investment either. Which type of storage gateway would you recommend?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: A. 

Each of the options is a valid configuration for a storage gateway. Of the options, file gateway provides an NFS-style protocol for transferring data to and from the gateway and therefore is the best option
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## U r helping a medium-sized business migrate its large datasets to cloud. The business has limited resources and has long used a tape backup system. It does not want to lose investment in the software & systems that already have been configured to use this backup system. Which storage gateway would u recommend?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: D. 

This is relatively easy because the word tape actually appears in both the question and the answer. 
A tape gateway backs up data in Amazon Glacier while providing a virtual tape infrastructure that many existing tape backup systems can utilize.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are tasked with prototyping a cloud-based storage solution for a small business. The business’s chief concern is low network latency, as its systems need near-instant access to all of its datasets. Which storage gateway would you recommend?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: C. 
A stored volume gateway stores data at the on-premises data store and backs up to S3 asynchronously to support disaster recovery. 
Most important, though, is that by storing data locally, network latency is minimal. Of the available options, only a stored volume gateway provides local data with this speed of access across an entire dataset.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## u r d SA for mapping division that has inherited a massive geospatial dataset from recent acquisition. The data is all on local disk drives, and u want to transition data to AWS. With datasets of over 10TB, what is best approach to get this data into AWS?

A. S3 with Transfer Acceleration
B. Cached volume gateway
C. Snowball
D. Shipping the drives to AWS


Answer: C. 

Anytime very large data needs to be moved into AWS, consider Snowball. 
Snowball is a physical device that allows data to physically sent to AWS rather than transferred over network. 
It is d only sol dat wil nt potentially cause disruptive network outage or slowdown.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following are not reasons to use a cached volumes storage gateway? (Choose two.)

A. You want low-latency access to your entire dataset.
B. You want to reduce the cost of on-site storage.
C. You want to support iSCSI storage volumes.
D. You want low-latency access to your most commonly accessed data.
E. A & C
F. B & C
G. B & D


Answer: A, C. 

A cached volume gateway stores the most commonly accessed data locally while keeping the entire dataset in S3. This has the effect of reducing the cost of storage on-site, because you need less. 
Since both of these are true, you need to select the other two options as reasons to not use a cached volumes gateway: A and C.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Which of the following storage gateway options is best for traditional backup applications?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: A. 

Be careful here. While it might seem at a glance that a tape gateway is best, most backup solutions do not employ tape backups. They use NFS mounts and file-based backups, which is exactly what a file gateway is best used for.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##37. Which of the following storage gateway options is best for applications where latency of specific portions of your entire dataset is the priority?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: B. 
A cached volume gateway is ideal when a portion of a dataset is at issue. The most used data will be cached, and therefore stored in the local cache on premises. If the entire dataset is needed, then a stored volume gateway is a better choice
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##38. Which of the following storage gateway options is best for applications where latency of your entire dataset is the priority?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: C. 
If the entire dataset is needed, then a stored volume gateway is a better choice than a cached volume gateway. The stored volume stores the entire dataset on premises and therefore is very fast for all data access.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##39. Which of the following storage gateway options is best for reducing the costs associated with an off-site disaster recovery solution?

A. File gateway
B. Cached volume gateway
C. Stored volume gateway
D. Tape gateway


Answer: D. 

A tape gateway is ideal for replacing off-site tape directories. The gateway is a virtual
tape directory and avoids the costs of transporting actual tapes to an expensive off-site
location.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##40. Which of the following storage classes is optimized for long-term data storage at the expense of retrieval time?

A. S3
B. S3-IA
C. S3 One Zone-IA
D. Glacier


Answer: D. This should be automatic: Glacier is the Amazon offering for long-term “on ice”
storage
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##41. Which of the following need to be considered across all regions in your account? (Choose two.)

A. Launch configurations
B. IAM users
C. EC2 instances
D. S3 bucket names


Answer: B, D. Launch configurations are specific to a region, as are EC2 instances. While S3
buckets are created in a region, their names are global. IAM users also exist across all of
your account.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##42. What HTTP code would you expect after a successful upload of an object to an S3 bucket?

A. HTTP 200
B. HTTP 307
C. HTTP 404
D. HTTP 501


Answer: A. HTTP 200 is the general return for success, and this is the case for S3 uploads as well.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##43. What is the durability of S3 One Zone-IA?

A. 99.0%
B. 99.9%
C. 99.99%
D. 99.999999999%


Answer: D. This is easy to miss. All S3 storage classes (S3 standard, S3-IA, and S3 One Zone-IA) share the same durability of 11 9s.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##44. What is the durability of S3-IA?

A. 99.0%
B. 99.9%
C. 99.99%
D. 99.999999999%



Answer: D. All S3 storage classes (S3 standard, S3-IA, and S3 One Zone-IA) share the same durability of 11 9s.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## What is the durability of S3?
A. 99.0%
B. 99.9%
C. 99.99%
D. 99.999999999%


Answer:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##46. What is the availability of S3 One Zone-IA?

A. 99.5%
B. 99.9%
C. 99.99%
D. 99.999999999%


Answer: 
A. While all S3 storage classes share the same durability, they have varying availability.
S3-IA has 99.9%, while S3 One Zone-IA is less (99.5%), and S3 standard is higher
(99.99%).

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##47. What is the availability of S3-IA?

A. 99.5%
B. 99.9%
C. 99.99%
D. 99.999999999%


Answer: B. 

While all S3 storage classes share the same durability, they have varying availability.
S3-IA has 99.9%, while S3 One Zone-IA is less (99.5%), and S3 standard is higher
(99.99%).
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##48. What is the availability of S3?
A. 99.5%
B. 99.9%
C. 99.99%
D. 99.999999999%


Answer: C. While all S3 storage classes share the same durability, S3 standard has the highest
availability, at 99.99%.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##49. Which S3 storage class supports SSL for data in transit?
A. S3
B. S3-IA
C. S3 One Zone-IA
D. All of the above


Answer: D. 

All of the S3 storage classes support both SSL for data in transit and encryption for
data at rest.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##50. Which S3 storage class supports encryption for data at rest?
A. S3
B. S3-IA
C. S3 One Zone-IA
D. All of the above


Answer: D. 

All of the S3 storage classes support both SSL for data in transit and encryption for data at rest.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##51. For which of the following storage classes do you need to specify a region?
A. S3
B. S3-IA
C. S3 One Zone-IA
D. All of the above



Answer: d

51. D. All S3 storage classes have buckets that can be created in a specific region. The objects
in the buckets are then stored in availability zones within that region, depending upon the
storage class.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##52. For which of the following storage classes do you need to specify an availability zone?

A. S3
B. S3-IA
C. S3 One Zone-IA
D. None of the above


Answer: d


52. D. While S3 does use availability zones to store objects in buckets, you do not choose the
availability zone yourself. Even S3 One Zone-IA does not allow you to specify the AZ
for use.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##53. How does S3 store your objects?

A. As key-value pairs
B. As relational entries.
C. Using a NoSQL interface
D. As blocks in a block storage


Answer: a


53. A. S3 storage is key based. Keys can be a string and the value is the uploaded object.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##54. In what ways can you access your data stored in S3 buckets? (Choose two.)

A. Through FTP access to the bucket
B. Through SFTP access to the bucket
C. Through a REST-based web service interface
D. Through the AWS console


Answer: cd


54. C, D. S3 does not provide SSH or SFTP access, nor standard FTP access. You can access
your data through the AWS console and through a REST interface via HTTP.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##55. Which of the following are true about S3 data access when traffic spikes (increases)? (Choose two.)

A. S3 will scale to handle the load if you have Auto Scaling set up.
B. S3 will scale automatically to ensure your service is not interrupted.
C. Scale spreads evenly across AWS network to minimize the effect of a spike.
D. A few instances are scaled up dramatically to minimize the effect of the spike.


Answer: bc


55. B, C. S3 is built to automatically scale in times of heavy application usage. There is
no requirement to enable Auto Scaling (A); rather, this happens automatically (so B is
correct). Further, S3 tends to scale evenly across the AWS network (C). Option D is the
opposite of what AWS intends.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##56. You have been tasked with helping a company migrate its expensive off-premises storage to AWS. It will still primarily back up files from its on-premises location to a local NAS. These files then need to be stored off-site (in AWS rather than the original off-site location). The company is concerned with durability and cost and wants to retain quick access to its files. What should you recommend?

A. Copying files from the NAS to an S3 standard class bucket
B. Copying files from the NAS to an S3 One Zone-IA class bucket
C. Copying the files from the NAS to EBS volumes with provisioned IOPS
D. Copying the files from the NAS to Amazon Glacier


Answer: b

56. B. When evaluating S3 storage, all storage classes have the same durability. For cost,
though, S3 One Zone-IA is the clear winner. Only Glacier is potentially less expensive but
does not provide the same quick file access that S3 One Zone-IA does.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##57. Which S3 storage class would you recommend if you were building out storage for an app that you anticipated growing in size exponentially over the next 12 months?

A. Amazon Glacier
B. S3 standard
C. S3-IA
D. There is not enough information to make a good decision.


Answer: b

57. D. This is nearly a trick question. S3 in general is built for scalability, and the different
storage classes are not substantially different in terms of how they can scale. However,
without knowing how quickly data retrieval must be, and the priorities of the data, it is
impossible to choose between S3 standard and S3-IA, and in some cases, even Glacier.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##58. How many S3 buckets can you create per AWS account, by default?

A. 25
B. 50
C. 100
D. There is not a default limit.


Answer: c

58. C. By default, all AWS accounts can create up to 100 buckets. However, this limit can
easily be raised by AWS if you request an upgrade.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##59. How are objects uploaded to S3 by default?

A. In parts
B. In a single operation
C. You must configure this option for each S3 bucket explicitly.
D. Via the REST API


Answer: b
59. B. S3 uploads are, by default, done via a single operation, usually via a single PUT
operation. AWS suggests that you can upload objects up to 100 MB before changing to
Multipart Upload.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##60. When does AWS suggest you start uploading objects via the Multipart Upload API?

A. When you’re uploading a lot of files at once
B. When you’re uploading files of 10 GB or more
C. When you have multiple applications uploading files to the same S3 bucket
D. When you need the greatest network throughput for uploads


Answer: b

60. B. Using the Multipart Upload is almost entirely a function of the size of the files being
uploaded. AWS recommends using it for any files greater than 100 MB, and 10 GB is
certainly large enough to benefit from Multipart Uploads.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##61. Which of the following are the ways you should consider using Multipart Upload? Choose two

A. For uploading large objects over a stable high-bandwidth network to maximize bandwidth

B. For uploading large objects to reduce the cost of ingress related to those objects

C. For uploading any size files over a spotty network to increase resiliency

D. For uploading files that must be appended to existing files


Answer: c

A, C. Multipart Upload is, as should be the easiest answer, ideal for large objects on
stable networks (A). But it also helps handle less-reliable networks as smaller parts can fail
while others get through, reducing the overall failure rate (C). There is no cost associated
with data ingress (B), and D doesn’t make much sense at all!

=======================================
############# Signed URL ##############

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##62. How is a presigned URL different from a normal URL? (Choose two.)

A. A presigned URL has permissions associated with certain objects provided by the creator of the URL.
B. A presigned URL has permissions associated with certain objects provided by the user of the URL.
C. A presigned URL allows access to private S3 buckets without requiring AWS credentials.
D. A presigned URL includes encrypted credentials as part of the URL.


Answer: A, C. 

Presigned URLs are created to allow users without AWS credentials to access specific resources (option C). 
And it’s the creator of the URL (option A) that assigns these permissions, rather than the user (option B). 
Finally, these credentials are associated with the URL but are not encrypted into the URL itself.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##63. Which of the following can be put behind a presigned URL?

A. An S3 object store
B. An EC2 instance with a web interface
C. An AWS CloudFront distribution
D. All of the above


Answer: D

Presigned URLs are not tied to specific AWS services. 
They are simply URLs that can point at anything a normal URL can point at, except that the creator can associate permissions and a timeout with the URL.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##64. How long is a presigned URL valid?

A. 60 seconds
B. 60 minutes
C. 24 hours
D. As long as it is configured to last


Answer: d


> A presigned URL is always configured at creation for a valid Time to Live (often referred to as TTL). This time can be very short, or quite long.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
### Your organization is using a CloudFront distribution to distribute content from an S3 bucket. It is required that only a particular set of users get access to certain content. How could this be accomplished? [WL332]

A. Create IAM Users for each user and then provide access to the S3 bucket content.
B. Create IAM Group for each set of users and then provide each Group access of the S3 bucket
C. Create CloudFront signed URLs and then distribute these URLs to the users.
D. Use IAM Polices for the underlying S3 buckets to restrict content. 


EXPLANATION:
Correct Answer - C

> Many companies that distribute content via the internet, want to restrict access to documents, business data, media streams, or content that is intended for the selected users, for example, users who have paid a fee. To securely serve this private content using CloudFront, you can do the following:

- Require that your users access your private content by using special CloudFront signed URLs or signed cookies. 
- Require that your users access your Amazon S3 content using CloudFront URLs, not Amazon S3 URLs. 
- Requiring CloudFront URLs isn't required, but we recommend it to prevent users from bypassing the restrictions that you specify in signed URLs or signed cookies.  

For more information on serving private content via CloudFront, please visit the following URL:
https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html#

=======================================
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##65. Which of the following HTTP methods with regard to S3 have eventual consistency? (Choose two.)

A. UPDATEs
B. DELETEs
C. PUTs of new objects
D. Overwrite PUTs


Answer:  b, d
65. B, D. Overwrite PUTs and DELETEs have eventual consistency. PUTs of new objects have write and then read consistency.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##66. Which of the following behaviors is consistent with how S3 handles object operations on a bucket?

A. A process writes a new object to Amazon S3 and immediately lists keys within its bucket. The new object does not appear in the list of keys.
B. A process deletes an object, attempts to immediately read the deleted object, and S3 still returns the deleted data.
C. A process deletes an object and immediately lists the keys in the bucket. S3 returns a list with the deleted object in the list.
D. All of the above


Answer: d

66. D. These are all consistent with S3 behavior. Option A could occur as the new object is
being propagated to additional S3 buckets. B and C could occur as a result of eventual
consistency, where a DELETE operation does not immediately appear.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##67. In which regions does Amazon S3 offer eventual consistency for overwrite PUTs and DELETEs?

A. All US regions
B. All US and EU regions
C. All regions
D. No regions, eventual consistency is not the model for overwrite PUTs.


Answer: c
67. C. All regions have eventual consistency for overwrite PUTs and DELETEs.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##68. Which of the following storage media are object based? (Choose two.)
A. S3-IA
B. EBS
C. EFS
D. S3 standard


Answer: ad

68. A, D. All S3 storage classes are object-based, while EBS and EFS are block-based.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##70. What is the consistency model in S3 for PUTs of new objects?

A. Write after read consistency
B. Read after write consistency
C. Eventual consistency
D. Synchronous consistency


Answer:
70. B. New objects uploaded via PUT are subject to read after write consistency. Overwrite
PUTs use the eventual consistency model.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##71. How many PUTs per second does S3 support?

A. 100
B. 1500
C. 3500
D. 5000


Answer: C
71. C. This is important because it reflects a recent change by AWS. Until 2018, there was a
hard limit on S3 of 100 PUTs per second, but that limit has now been raised to 3500 PUTs
per second.

=======================================
######### S3 BUCKET NAME/URL ##########
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##72. You have been asked to create a new S3 bucket with the name prototypeBucket32 in the US West region. What would the URL for this bucket be?
A. https://s3-us-east-1.amazonaws.com/prototypeBucket32
B. https://s3-us-west-1.amazonaws.com/prototypeBucket32
C. https://s3.prototypeBucket32-us-east-1.amazonaws.com/
D. https://s3-prototypeBucket32.us-east-1.amazonaws.com/


Answer: b

> S3 buckets have names based upon the S3 identifier (s3), the region (us-west-1 in this case), and the amazonaws.com domain. 
- Then, the bucket name appears after the domain.
That results in B, https://s3-us-west-1.amazonaws.com/prototypeBucket32. 

Option A has an incorrect region, and both C and D have the bucket name in the domain, which is incorrect.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##73. What unique domain name do S3 buckets created in US East (N. Virginia) have, as compared to other regions?

A. s3.amazonaws.com
B. s3-us-east-1.amazonaws.com
C. s3-us-east.amazonaws.com
D. s3-amazonaws.com


Answer: A

73. A. S3 buckets have names based upon the S3 identifier (s3), the region (us-east-1 in this case), and the amazonaws.com domain. 
- Then, the bucket name appears after the domain. That results in a URL like https://s3-us-east-1.amazonaws.com/prototypeBucket32. 

However, buckets in US East are a special case and should use the special, unique endpoint s3.amazonaws.com (option A).
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##74. Which of the following are valid domain names for S3 buckets? (Choose two.)

A. s3.us-east-1.amazonaws.com
B. s3-us-west-2.amazonaws.com
C. s3.amazonaws.com
D. s3-jp-west-2.amazonaws.com


Answer: B, C

Option A is not the correct format; s3 should be separated from the region with a dash (-). 
Option B is valid, and option C is the correct unique URL for US East (N.Virginia). 
Option D is the right format, but jp-west-2 is not an AWS region.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##75. What are the two styles of URLs that AWS supports for S3 bucket access? (Choose two.)

A. Virtual-hosted-style URLs
B. Domain-hosted-style URLs
C. Apex zone record URLs
D. Path-style URLs


Answer: A,D 

S3 supports 2 styles of bucket URLs: 
1. Virtual-hosted-style 
-  http://bucket.s3-aws-region.amazonaws.com

2. Path-Style URLs are the traditional URLs you’ve seen:
-  https://s3-aws-region.amazonaws.com/bucket-name

=======================================
########### S3 ENCRYPTION #############
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## What two methods would allow you to encrypt data stored in S3 buckets at rest? (Choose 2)

a. Using AWS S3 server side encryption with Key Management Service keys or Customer-Provided keys
b. Encrypt the data at the source (EC2 or by application) before transferring it to S3 using the Client's CMK keys
c. Make use of AWS 53 bucket policies to control access to the data at rest
d. Ensure data is encrypted in-transit using SSL, this will ensure it is encrypted when it arrives at S3


Answer : A, B
=======================================
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## An AWS Solutions Architect who is designing a solution to store and archive corporate documents has determined Amazon Glacier as the right choice. An important requirement is that the data must be delivered within 10 minutes of a retrieval request. Which feature in Amazon Glacier could help to meet this requirement?

A. Vault Lock
B. Expedited retrieval
C. Bulk retrieval
D. Standard retrieval


ANSWER : B

EXPLANATION : 
AWS Documentation mentions the following:

Expedited retrievals allow you to access data in 1–5 minutes for a flat rate of $0.03 per GB retrieved. Expedited retrievals allow you to quickly access your data when occasional urgent requests for a subset of archives are required.

The Vault Lock and Standard Retrieval are standard with 3-5 hours retrieval time while Bulk retrievals which can be considered the cheapest option have 5-12 hours retrieval time. 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## An application reads and writes objects to an S3 bucket. When the application is fully deployed, the read/write traffic is expected to be 5,000 requests per second for the addition of data and 7,000 requests per second for the retrieval of data. What would the architect do to maximize the Amazon S3 performance? [WL113]

A. Use as many S3 prefixes as you need in parallel to achieve the required throughput.
B. Use the STANDARD_IA storage class. 
C. Prefix each object name with a hex hash key along with the current date. 
D. Enable versioning on the S3 bucket.


ANSWER : C

EXPLANATION : 
NOTE: Based on the S3 new performance announcement, "S3 request rate performance increase removes any previous guidance to randomize object prefixes to achieve faster performance." But Amazon exam questions and answers have not yet been updated. So, Option C is the correct answer as per AWS exam.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## A Solutions Architect is designing a highly scalable system to track records. These records must remain available for immediate download for up to three months and then must be deleted. What is the most appropriate decision for this use case?

A. Store the files in Amazon EBS and create a Lifecycle Policy to remove files after 3 months.
B. Store the files in Amazon S3 and create a Lifecycle Policy to remove files after 3 months.
C. Store the files in Amazon Glacier and create a Lifecycle Policy to remove files after 3 months.
D. Store the files in Amazon EFS and create a Lifecycle Policy to remove files after 3 months.


ANSWER : B

EXPLANATION : 
Option A is incorrect since the records need to be stored in a highly scalable system.
Option C is incorrect since the records must be available for immediate download.
Option D is incorrect since EFS lifecycle management is used to migrate files that have not been accessed for a certain period of time to the Infrequent Access storage class. Files moved to this storage remain indefinitely, and not get deleted. And due to this reason, this option is not correct.
AWS Documentation mentions the following about Lifecycle Policies:

Lifecycle configuration enables you to specify the Lifecycle Management of objects in a bucket. The configuration is a set of one or more rules, where each rule defines an action for Amazon S3 to apply to a group of objects. These actions can be classified as follows:

Transition actions – In which you define when the transition of the object occurs to another storage class. For example, you may choose to transition objects to the STANDARD_IA (IA, for infrequent access) storage class 30 days after creation or archive objects to the GLACIER storage class one year after creation.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You have developed a new web application on AWS for a real estate firm. It has a web interface where real estate employees upload photos of newly constructed houses in S3 buckets. Prospective buyer’s login to the website and access photos. The marketing team has initiated an intensive marketing event to promote new housing schemes which will lead to customers who frequently access these images. As this is a new application, you have no projection of traffic. You have created Auto Scaling across multiple instance types for these web servers, but you also need to optimize the cost for storage. You don’t want to compromise on latency & all images should be downloaded instantaneously without any outage. Which of the following is a recommended storage solution to meet this requirement? [WL123]

A. Use One Zone-IA storage class to store all images.
B. Use Standard-IA to store all images.
C. Use S3 Intelligent-Tiering storage class.
D. Use Standard storage class, use Storage class analytics to identify & move objects using lifecycle policies. 

ANSWER : C

EXPLANATION : 

When access pattern to web application using S3 storage buckets is unpredictable, you can use S3 intelligent-Tiering storage class. S3 Intelligent-Tiering storage class includes two access tiers: frequent access and infrequent access. Based upon access patterns, it moves data between these tiers which helps in cost saving. S3 Intelligent-Tiering storage class have the same performance as that of Standard storage class.

Option A is incorrect. Although it will save cost, it will not provide any protection in case of AZ failure. Also, this class is suitable for infrequently accessed data & not for frequently access data.
Option B is incorrect as Standard-IA storage class is for infrequently accessed data & there are retrieval charges associated. In the above requirement, you do not have any projections of data being accessed which may result in a higher cost.
Option D is incorrect. It has operational overhead to setup Storage class analytics & moves objects between various classes. Also, since the access pattern is undetermined, this will run into a costlier option.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 3. You have created an S3 bucket in us-east-1 region with default configuration. You are located in Asia and deleted an object in the bucket using AWS CLI. However, when you tried to list the objects in the bucket, you still see the object you deleted. You are even able to download the object. What could have caused this behaviour?

A. Cross region deletes are not supported by AWS
B. AWS provides eventual consistency for DELETES.
C. AWS keeps copy of deleted object for 7 days in STANDARD storage.
D. AWS provides strong consistency for DELETES.


Answer: B
