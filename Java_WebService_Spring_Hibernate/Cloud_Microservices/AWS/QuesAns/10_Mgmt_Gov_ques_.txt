=======================================
###### Management & Governance ########

############## CloudTrail #############
############## CloudWatch #############
############# CloudFormation ##########
############# Trusted Advisor #########
############ AWS Config ###############
############ AWS OpsWorks #############
########### AWS Service Catalog #######
############## AWS RAM ################
###### AWS Systems Manager(SM) ########
=======================================
############## CloudTrail #############


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 21: A Solutions Architect is working for a company which has multiple VPCs in various AWS regions. The Architect is assigned to set up a logging system which will track all of the changes made to their AWS resources in all regions, including the configurations made in IAM, CloudFront, AWS WAF, and Route 53. In order to pass the compliance requirements, the solution must ensure the security, integrity, and durability of the log data. It should also provide an event history of all API calls made in AWS Management Console and AWS CLI.
Which of the following solutions is the best fit for this scenario? [UD121]

A. Set up a new CloudWatch trail in a new S3 bucket using the CloudTrail console and also pass the --is-multi-region-trail parameter then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.

B. Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.


C. Set up a new CloudWatch trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.


D. Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --no-include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.


EXPLANATION: 
ANSWER : B
An event in CloudTrail is the record of an activity in an AWS account. This activity can be an action taken by a user, role, or service that is monitorable by CloudTrail. CloudTrail events provide a history of both API and non-API account activity made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. There are two types of events that can be logged in CloudTrail: management events and data events. By default, trails log management events, but not data events.

A trail can be applied to all regions or a single region. As a best practice, create a trail that applies to all regions in the AWS partition in which you are working. This is the default setting when you create a trail in the CloudTrail console.
For most services, events are recorded in the region where the action occurred. For global services such as AWS Identity and Access Management (IAM), AWS STS, Amazon CloudFront, and Route 53, events are delivered to any trail that includes global services, and are logged as occurring in US East (N. Virginia) Region.
In this scenario, the company requires a secure and durable logging solution that will track all of the activities of all AWS resources on all regions. CloudTrail can be used for this case with multi-region trail enabled, however, it will only cover the activities of the regional services (EC2, S3, RDS etc.) and not for global services such as IAM, CloudFront, AWS WAF, and Route 53. In order to satisfy the requirement, you have to add the --include-global-service-events parameter in your AWS CLI command.
The option that says: Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies is correct because it provides security, integrity, and durability to your log data and in addition, it has the -include-global-service-events parameter enabled which will also include activity from global services such as IAM, Route 53, AWS WAF, and CloudFront.
The option that says: Set up a new CloudWatch trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies is incorrect because you need to use CloudTrail instead of CloudWatch.
The option that says: Set up a new CloudWatch trail in a new S3 bucket using the CloudTrail console and also pass the --is-multi-region-trail parameter then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies is incorrect because you need to use CloudTrail instead of CloudWatch. In addition, the --include-global-service-events parameter is also missing in this setup.
The option that says: Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --no-include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies is incorrect because the --is-multi-region-trail is not enough as you also need to add the --include-global-service-events parameter and not --no-include-global-service-events. Plus, you cannot enable the Global Service Events using the CloudTrail console but by using AWS CLI.

References:
https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.html#cloudtrail-concepts-global-service-events
http://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html
https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail-by-using-the-aws-cli.html

Check out this AWS CloudTrail Cheat Sheet:
https://tutorialsdojo.com/aws-cheat-sheet-aws-cloudtrail/
=======================================
############## CloudWatch #############
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 15. An application running video editing software is using significant memory on an Amazon EC2 instance. How can a user track memory usage on the Amazon EC2 instance? [DC15]

A. Call Amazon CloudWatch to retrieve the memory usage metric data that exists for the EC2 instance
B. Assign an TAM role to the EC2 instance with an TAM policy granting access to the desired metric
C. Use an instance type that supports memory usage reporting to a metric by default
D. Install the CloudWatch agent on the EC2 instance to push memory usage to an Amazon CloudWatch custom metric


EXPLANATION :
ANSWER : D
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
## Your company currently has a set of EC2 Instances hosted in AWS. The states of these instances need to be monitored and each state change needs to be recorded. Which step could be helpful to fulfill this requirement? (SELECT TWO) [WL204]

A. Use CloudWatch logs to store the state change of the instances. 
B. Create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance
C. Use SQS to trigger a record to be added to a DynamoDB table.  
D. Use AWS Lambda to store a change record in a DynamoDB table. 



ANSWER : A, B

EXPLANATION: 
Create Alarms That Stop, Terminate, Reboot, or Recover an Instance 

Using Amazon CloudWatch alarm actions, you can create alarms that automatically stop, terminate, reboot or recover your instances. 
- You can use the stop or terminate actions to save money when you no longer need an instance. 
- You can use the reboot and recover actions to automatically reboot those instances or recover them onto new hardware if a system impairment occurs.

The AWSServiceRoleForCloudWatchEvents service-linked role enables AWS to perform alarm actions on your behalf. 
- The first time you create an alarm in the AWS Management Console, the IAM CLI, or the IAM API, CloudWatch creates the service-linked role for you.

> There are a number of scenarios in which you might want to automatically stop or terminate your instance. 
- For example, you might have instances dedicated to batch payroll processing jobs or scientific computing tasks that run for a period of time and then complete their work. 
- Rather than letting those instances sit idle (and accrue charges), you can stop or terminate them, which could help you to save money. 
- The main difference between using the stop and the terminate alarm actions is that you can easily restart a stopped instance if you need to run it again later, and you can keep the same instance ID and root volume. However, you cannot restart a terminated instance instead, you must launch a new instance.

- You can add the stop, terminate, reboot or recover actions to any alarm that is set on an Amazon EC2 per-instance metric, including basic and detailed monitoring metrics provided by Amazon CloudWatch (in the AWS/EC2 namespace), as well as any custom metrics that include the InstanceId dimension, as long as its value refers to a valid running Amazon EC2 instance.

For more information on Amazon EC2, please visit the following URL: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-ug.pdf

Option A is correct. Using Cloudwatch logs collect, store, view, and search logs from AWS and non-AWS resources.
Option B is correct. CloudWatch alarms are used to trigger notifications for any metric. Alarms can go to auto-scaling, EC2 actions(stop, terminate, recover, or reboot) and SNS notifications.
Option C is incorrect as SQS cannot be used for monitoring.
Option D is incorrect as AWS Lambda cannot be used for monitoring.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
### 4: Your cloud architecture is composed of Linux and Windows EC2 instances which process high volumes of financial data 24 hours a day, 7 days a week. To ensure high availability of your systems, you are required to monitor the memory and disk utilization of all of your instances.   
Which of the following is the most suitable monitoring solution to implement? [UD104]

A. Enable the Enhanced Monitoring option in EC2 and install CloudWatch agent to all of your EC2 instances to be able to view the memory and disk utilization in the CloudWatch dashboard.

B. Use the default CloudWatch configuration to your EC2 instances where the memory and disk utilization metrics are already available. Install the AWS Systems Manager (SSM) Agent to all of your EC2 instances.

C. Install the CloudWatch agent to all of your EC2 instances which gathers the memory and disk utilization data. View the custom metrics in the Amazon CloudWatch console.

D. Use Amazon Inspector and install the Inspector agent to all of your EC2 instances.


EXPLANATION: CloudWatch
Answer: C

CloudWatch has available Amazon EC2 Metrics for you to use for monitoring CPU utilization, Network utilization, Disk performance, and Disk Reads/Writes. In case that you need to monitor the below items, you need to prepare a custom metric using a Perl or other shell script, as there are no ready to use metrics for these:
Memory utilization
disk swap utilization
disk space utilization
page file utilization
log collection

Take note that there is a multi-platform CloudWatch agent which can be installed on both Linux and Windows-based instances. 
- You can use a single agent to collect both system metrics and log files from Amazon EC2 instances and on-premises servers. 
- This agent supports both Windows Server and Linux and enables you to select the metrics to be collected, including sub-resource metrics such as per-CPU core. 
- It is recommended that you use the new agent instead of the older monitoring scripts to collect metrics and logs.

The option that says: Use the default CloudWatch configuration to your EC2 instances where the memory and disk utilization metrics are already available. Install the AWS Systems Manager (SSM) Agent to all of your EC2 instances is incorrect 
- because, by default, CloudWatch does not automatically provide memory and disk utilization metrics of your instances. 
- You have to set up custom CloudWatch metrics to monitor the memory, disk swap, disk space and page file utilization of your instances.

The option that says: Enable the Enhanced Monitoring option in EC2 and install CloudWatch agent to all of your EC2 instances to be able to view the memory and disk utilization in the CloudWatch dashboard is incorrect because 
- Enhanced Monitoring is a feature of RDS and not of CloudWatch.

Using Amazon Inspector and installing the Inspector agent to all of your EC2 instances is incorrect because 
- Amazon Inspector is an automated security assessment service that helps you test the network accessibility of your Amazon EC2 instances and the security state of your applications running on the instances.
- It does not provide a custom metric to track the memory and disk utilization of each and every EC2 instance in your VPC.

References:
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script

Check out this Amazon CloudWatch Cheat Sheet:
https://tutorialsdojo.com/aws-cheat-sheet-amazon-cloudwatch/

CloudWatch Agent vs SSM Agent vs Custom Daemon Scripts:
https://tutorialsdojo.com/aws-cheat-sheet-cloudwatch-agent-vs-ssm-agent-vs-custom-daemon-scripts/

Comparison of AWS Services Cheat Sheets:
https://tutorialsdojo.com/comparison-of-aws-services-for-udemy-students/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
### 9: An application is hosted in an AWS Fargate cluster that runs a batch job whenever an object is loaded on an Amazon S3 bucket. The minimum number of ECS Tasks is initially set to 1 to save on costs, and it will only increase the task count based on the new objects uploaded on the S3 bucket. Once processing is done, the bucket becomes empty and the ECS Task count should be back to 1.
Which is the most suitable option to implement with the LEAST amount of effort? [UD109]

A. Set up an alarm in CloudWatch to monitor CloudTrail since this S3 object-level operations are recorded on CloudTrail. Set two alarm actions to update ECS task count to scale-out/scale-in depending on the S3 event.

B. Set up a CloudWatch Event rule to detect S3 object PUT operations and set the target to a Lambda function that will run Amazon ECS API command to increase the number of tasks on ECS. Create another rule to detect S3 DELETE operations and run the Lambda function to reduce the number of ECS tasks.

C. Set up an alarm in CloudWatch to monitor CloudTrail since the S3 object-level operations are recorded on CloudTrail. Create two Lambda functions for increasing/decreasing the ECS task count. Set these as respective targets for the CloudWatch Alarm depending on the S3 event.

D. Set up a CloudWatch Event rule to detect S3 object PUT operations and set the target to the ECS cluster with the increased number of tasks. Create another rule to detect S3 DELETE operations and set the target to the ECS Cluster with 1 as the Task count.


EXPLANATION: 
ANSWER : D

> You can use CloudWatch Events to run Amazon ECS tasks when certain AWS events occur. 
- You can set up a CloudWatch Events rule that runs an Amazon ECS task whenever a file is uploaded to a certain Amazon S3 bucket using the Amazon S3 PUT operation. 
- You can also declare a reduced number of ECS tasks whenever a file is deleted on the S3 bucket using the DELETE operation.

> First, you must create a CloudWatch Events rule for the S3 service that will watch for object-level operations – PUT and DELETE objects.
- For object-level operations, it is required to create a CloudTrail trail first. 
- On the Targets section, select the “ECS task” and input the needed values such as the cluster name, task definition and the task count.
- You need two rules – one for the scale-up and another for the scale-down of the ECS task count.

=======================================
########### CloudFormation ############

## A consulting firm repeatedly builds large architectures for their customers using AWS resources from several AWS services including IAM, Amazon EC2, Amazon RDS, DynamoDB and Amazon VPC. The consultants have architecture diagrams for each of their architectures, and are frustrated that they cannot use them to automatically create their resources. Which service should provide immediate benefits to the organization?

A. AWS Beanstalk
B. AWS CloudFormation
C. AWS CodeBuild
D. AWS CodeDeploy


ANSWER : B

EXPLANATION : 
AWS CloudFormation is a service that helps you model and set up your Amazon Web Service resources so that you can spend less time managing those resources and more time focusing on your applications that run in AWS. You create a template that describes all the AWS resources that you want (like Amazon EC2 instances or Amazon RDS DB instances), and AWS CloudFormation takes care of provisioning and configuring those resources for you.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## You are working for a start-up company that develops mobile gaming applications using AWS resources. For creating AWS resources, the project team is using CloudFormation Templates. The Project Team is concerned about the changes made in EC2 instance properties by the Operations Team, apart from parameters specified in CloudFormation Templates. To observe changes in AWS EC2 instance, you advise using CloudFormation Drift Detection. After Drift detection, when you check drift status for all AWS EC2 instance, drift for certain property values having default values for resource properties is not displayed. What would you do to include these resources properties to be captured in CloudFormation Drift Detection?

A. Run CloudFormation Drift Detection on individual stack resources instead of entire CloudFormation stack. 
B. Explicitly set the property value, which can be the same as the default value. 
C. Manually check these resources as this is not supported in CloudFormation Drift Detection. 
D. Assign Read permission to CloudFormation Drift Detection to determine drift. 

ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## A company has an EC2 instance running and suddenly the server was terminated. Its suspected that a junior developer may have terminated this instance by mistake. Which AWS service will help determining who was responsible?

CloudTrail
Trusted Advisor
AWS Inspector
CloudWatch Logs


EXPLANATION : CloudTrail
ANSWER : A

=======================================
############# Trusted Advisor #########

=======================================
############ AWS Config ###############
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 2:WL7: Your company has an AWS account and a lot of resources defined in the Frankfurt region. They want to track the changes to the resources in their account. Which of the following should be used for this purpose? 

A. AWS Config
B. AWS CloudTrail
C. AWS CloudWatch
D. AWS Opswork


EXPLANATION:
Answer – A

The AWS Documentation mentions the following

> AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. 
- Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. 
- With Config, you can review changes in configurations and relationships between AWS resources, dive into detailed resource configuration histories, and determine your overall compliance against the configurations specified in your internal guidelines. 
- This enables you to simplify compliance auditing, security analysis, change management, and operational troubleshooting. 

Option B is invalid because this is an API monitoring service
Option C is invalid because this is a metric and logging service
Option D is invalid because is used to deploy stacks of resources

For more information on AWS Config , please refer to the below URL

https://aws.amazon.com/config/
CloudWatch and Config serve distinct use cases for monitoring and complements each other from AWS ecosystem. 
Config is typically used for auditing and compliance purposes across organizations to verify whether AWS resource changes being made are per compliance rules. Some of the typical compliance rules are as follows:
IAM user should be part of one of the IAM groups
None of the S3 bucket should be publicly accessible
EC2 resources should be launched in private subnets only, so that it cannot be accessed outside VPC
Server access logging should be enabled on S3 buckets
Certain IAM policy should not be modified or it should not be attached to any user. For e.g AdministratorAccess IAM policy

Above compliance rules vary from one organization to another depending upon legal agreements signed between organization/client and government/customers

CloudWatch is designed to provide performance information about AWS resources such as EC2, Lambda etc. Developers can use information from CloudWatch to identify bottlenecks in applications or workflows. 
Cloudwatch will help you to send alerts when CPU /Memory utilization reaches a certain threshold and browse metrics associated with CPU/Network to identify operational and security issues , if any 


Please find below  sample config rule for S3 service:



Here is the screenshot, where you could see the changes/revisions made on one of the S3 buckets over a period of time

Cloudwatch would help to monitor AWS resource "metric/event" changes , however Cloudtrail is  used for monitoring AWS resource "configuration" changes. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##8: A new company policy requires IAM users to change their passwords’ minimum length to 12 characters. After a random inspection, you found out that there are still employees who do not follow the policy.
How can you automatically check and evaluate whether the current password policy for an account complies with the company password policy? [UD408]

A. Create a CloudTrail trail. Filter the result by setting the attribute to “Event Name” and lookup value to “ChangePassword”. This easily gives you the list of users who have made changes to their passwords.

B. Create a Scheduled Lambda Function that will run a custom script to check compliance against changes made to the passwords periodically.

C. Create a rule in the Amazon CloudWatch event. Build an event pattern to match events on IAM. Set the event name to “ChangePassword” in the event pattern. Configure SNS to send notifications to you whenever a user has made changes to his password.

D. Configure AWS Config to trigger an evaluation that will check the compliance for a user’s password periodically.


EXPLANATION : 
ANSWER : D

AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations.


In the scenario given, we can utilize AWS Config to check for compliance on the password policy by configuring the Config rule to check the IAM_PASSWORD_POLICY on an account. Additionally, because Config integrates with AWS Organizations, we can improve the set up to aggregate compliance information across accounts to a central dashboard.

Hence, the correct answer is: Configure AWS Config to trigger an evaluation that will check the compliance for a user’s password periodically.

Create a CloudTrail trail. Filter the result by setting the attribute to “Event Name” and lookup value to “ChangePassword”. This easily gives you the list of users who have made changes to their passwords is incorrect because this setup will just give you the name of the users who have made changes to their respective passwords. It will not give you the ability to check whether their passwords have met the required minimum length.

Create a Scheduled Lambda function that will run a custom script to check compliance against changes made to the passwords periodically is a valid solution but still incorrect. AWS Config is already integrated with AWS Lambda. You don't have to create and manage your own Lambda function. You just have to define a Config rule where you will check compliance, and Lambda will process the evaluation. Moreover, you can't directly create a scheduled function by using Lambda itself. You have to create a rule in AWS CloudWatch Events to run the Lambda functions on the schedule that you define.

Create a rule in the Amazon CloudWatch event. Build an event pattern to match events on IAM. Set the event name to “ChangePassword” in the event pattern. Configure SNS to send notifications to you whenever a user has made changes to his password is incorrect because this setup will just alert you whenever a user changes his password. Sure, you’ll have information about who made changes, but that is not enough to check whether it complies with the required minimum password length. This can be easily done in AWS Config.


References:
https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config-rules.html
https://aws.amazon.com/config/


Check out this AWS Config Cheat Sheet:
https://tutorialsdojo.com/aws-config/

=======================================
############ AWS OpsWorks #############
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Your company requires a Stack-based model for its resources in AWS. There is a need to have different stacks for the Development and Production environments. Which of the following can be used for this? [WL336]

A. Use EC2 tags to define different stack layers for your resources.
B. Define the metadata for the different layers in DynamoDB.
C. Use AWS OpsWorks to define the different layers for your application.
D. Use AWS Config to define the different layers for your application. 


EXPLANATION:
Correct Answer - C

The requirement can be fulfilled via the OpsWorks service. 

> AWS OpsWorks Stacks lets you manage applications and servers on AWS and on-premises. 
- With OpsWorks Stacks, you can model your application as a stack containing different layers, such as load balancing, database, and application server.
- You can deploy and configure Amazon EC2 instances in each layer or connect other resources such as Amazon RDS databases. 

For more information on OpsWorks stacks, please visit the following URL:
https://aws.amazon.com/opsworks/stacks/

A stack is basically a collection of instances that are managed together for serving a common task. 
Consider a sample stack whose purpose is to serve web applications. It will be comprised of the following instances. 
A set of application server instances, each of which handles a portion of the incoming traffic. 
A load balancer instance, which takes incoming traffic and distributes it across the application servers. 
A database instance, which serves as a back-end data store for the application servers. 
A common practice is to have multiple stacks that represent different environments. A typical set of stacks consists of:

A development stack to be used by developers to add features, fix bugs, and perform other development and maintenance tasks. 
A staging stack to verify updates or fixes before exposing them publicly. 
A production stack, which is the public-facing version that handles incoming requests from users. 
For more information, please see the link given below:

https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks.html

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


=======================================
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


=======================================
########### CloudFormation ############

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


=======================================
########### CloudFormation ############

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 

=======================================
########### AWS Service Catalog #######
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## 


ANSWER : 

EXPLANATION : 

=======================================
############## AWS RAM ################


=======================================
## Which AWS service will help you visualize your day to day costs in AWS?

AWS Cost Explorer
AWS TCO
AWS Budgets
AWS Trusted Advisor


EXPLANATION : 
ANSWER : A

=======================================
###### AWS Systems Manager(SM) ########

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##31:UD5: You recently launched a fleet of on-demand EC2 instances to host a massively multiplayer online role-playing game (MMORPG) server in your VPC. The EC2 instances are configured with Auto Scaling and AWS Systems Manager. What can you use to configure your EC2 instances without having to establish a RDP or SSH connection to each instance?

A. Run Command
B. AWS CodePipeline
C. AWS Config
D. EC2Config


EXPLANATION : 
ANSWER : A

You can use Run Command from the console to configure instances without having to login to each instance.

> AWS Systems Manager Run Command lets you remotely and securely manage the configuration of your managed instances. 
- A managed instance is any EC2 instance or on-premises machine in your hybrid environment that has been configured for Systems Manager. 

> Run Command enables you to automate common administrative tasks and perform ad-hoc configuration changes at scale. 
- You can use Run Command from the AWS console, the AWS CLI, AWS Tools for Windows PowerShell, or the AWS SDKs. 
- Run Command is offered at no additional cost.

Reference:
https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html

Check out this Amazon EC2 Cheat Sheet:
https://tutorialsdojo.com/aws-cheat-sheet-amazon-elastic-compute-cloud-amazon-ec2/
